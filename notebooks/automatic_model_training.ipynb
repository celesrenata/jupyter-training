{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1eab0b3",
   "metadata": {
    "id": "c1eab0b3"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882058c5",
   "metadata": {
    "id": "882058c5"
   },
   "source": [
    "This notebook demonstrates how to train custom openWakeWord models using pre-defined datasets and an automated process for dataset generation and training. While not guaranteed to always produce the best performing model, the methods shown in this notebook often produce baseline models with releatively strong performance.\n",
    "\n",
    "Manual data preparation and model training (e.g., see the [training models](training_models.ipynb) notebook) remains an option for when full control over the model development process is needed.\n",
    "\n",
    "At a high level, the automatic training process takes advantages of several techniques to try and produce a good model, including:\n",
    "\n",
    "- Early-stopping and checkpoint averaging (similar to [stochastic weight averaging](https://arxiv.org/abs/1803.05407)) to search for the best models found during training, according to the validation data\n",
    "- Variable learning rates with cosine decay and multiple cycles\n",
    "- Adaptive batch construction to focus on only high-loss examples when the model begins to converge, combined with gradient accumulation to ensure that batch sizes are still large enough for stable training\n",
    "- Cycical weight schedules for negative examples to help the model reduce false-positive rates\n",
    "\n",
    "See the contents of the `train.py` file for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d031b",
   "metadata": {
    "id": "e08d031b"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee78c37",
   "metadata": {
    "id": "aee78c37"
   },
   "source": [
    "To begin, we'll need to install the requirements for training custom models. In particular, a relatively recent version of Pytorch and custom fork of the [piper-sample-generator](https://github.com/dscripka/piper-sample-generator) library for generating synthetic examples for the custom model.\n",
    "\n",
    "**Important Note!** Currently, automated model training is only supported on linux systems due to the requirements of the text to speech library used for synthetic sample generation (Piper). It may be possible to use Piper on Windows/Mac systems, but that has not (yet) been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1227eb",
   "metadata": {
    "id": "4b1227eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'piper-sample-generator'...\n",
      "remote: Enumerating objects: 161, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 161 (delta 64), reused 62 (delta 50), pack-reused 69 (from 1)\u001b[K\n",
      "Receiving objects: 100% (161/161), 1.04 MiB | 9.03 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "--2026-01-18 08:08:02--  https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "302 Foundest sent, awaiting response... \n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A44%3A33Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A43%3A48Z&ske=2026-01-18T08%3A44%3A33Z&sks=b&skv=2018-11-09&sig=aV7wROAhFXiFltjY67GBXvXwEnMomSKN%2BAM4Y1u1kQ4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNzI4MywibmJmIjoxNzY4NzIzNjgzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.BNzBlWvoCABg1AeMFumcK2s0KmougmLAlQtwMXZlnqk&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2026-01-18 08:08:03--  https://release-assets.githubusercontent.com/github-production-release-asset/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A44%3A33Z&rscd=attachment%3B+filename%3Den_US-libritts_r-medium.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A43%3A48Z&ske=2026-01-18T08%3A44%3A33Z&sks=b&skv=2018-11-09&sig=aV7wROAhFXiFltjY67GBXvXwEnMomSKN%2BAM4Y1u1kQ4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNzI4MywibmJmIjoxNzY4NzIzNjgzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.BNzBlWvoCABg1AeMFumcK2s0KmougmLAlQtwMXZlnqk&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream\n",
      "185.199.111.133, 185.199.109.133, 185.199.110.133, ...e-assets.githubusercontent.com)... \n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 204089915 (195M) [application/octet-stream]\n",
      "Saving to: ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’\n",
      "\n",
      "piper-sample-genera 100%[===================>] 194.63M   103MB/s    in 1.9s    \n",
      "\n",
      "2026-01-18 08:08:05 (103 MB/s) - ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’ saved [204089915/204089915]\n",
      "\n",
      "Requirement already satisfied: piper-phonemize in ./.local/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: webrtcvad in ./.local/lib/python3.10/site-packages (2.0.10)\n",
      "Cloning into 'openwakeword'...\n",
      "remote: Enumerating objects: 1173, done.\u001b[K\n",
      "remote: Counting objects: 100% (614/614), done.\u001b[K\n",
      "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
      "remote: Total 1173 (delta 499), reused 457 (delta 453), pack-reused 559 (from 2)\u001b[K\n",
      "Receiving objects: 100% (1173/1173), 3.21 MiB | 19.10 MiB/s, done.\n",
      "Resolving deltas: 100% (715/715), done.\n",
      "Requirement already satisfied: numpy<2.0 in ./.local/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting pyarrow<15.0.0\n",
      "  Using cached pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./.local/lib/python3.10/site-packages (from pyarrow<15.0.0) (1.26.4)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 22.0.0\n",
      "    Uninstalling pyarrow-22.0.0:\n",
      "      Successfully uninstalled pyarrow-22.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-14.0.2\n",
      "Requirement already satisfied: mutagen==1.47.0 in ./.local/lib/python3.10/site-packages (1.47.0)\n",
      "Requirement already satisfied: torchinfo==1.8.0 in ./.local/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: torchmetrics==1.2.0 in ./.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in ./.local/lib/python3.10/site-packages (from torchmetrics==1.2.0) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in ./.local/lib/python3.10/site-packages (from torchmetrics==1.2.0) (2.0.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./.local/lib/python3.10/site-packages (from torchmetrics==1.2.0) (0.15.2)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (80.9.0)\n",
      "Requirement already satisfied: typing_extensions in ./.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.15.0)\n",
      "Requirement already satisfied: packaging>=17.1 in ./.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (25.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.20.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.14.3)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.7.101)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.6)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.14.0)\n",
      "Requirement already satisfied: wheel in ./.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics==1.2.0) (0.45.1)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics==1.2.0) (18.1.8)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics==1.2.0) (4.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
      "Requirement already satisfied: speechbrain==0.5.14 in ./.local/lib/python3.10/site-packages (0.5.14)\n",
      "Requirement already satisfied: hyperpyyaml in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (1.2.3)\n",
      "Requirement already satisfied: torch>=1.9 in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (2.0.1)\n",
      "Requirement already satisfied: torchaudio in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (2.0.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.14) (1.15.3)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (25.0)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (0.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.14) (1.5.3)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.10/site-packages (from speechbrain==0.5.14) (1.3.2)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (2.14.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.7.99)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (3.20.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.4.0.1)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (10.9.0.58)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.14) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in ./.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->speechbrain==0.5.14) (0.45.1)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->speechbrain==0.5.14) (80.9.0)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->speechbrain==0.5.14) (4.2.1)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->speechbrain==0.5.14) (18.1.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (2025.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.3)\n",
      "Requirement already satisfied: typer-slim in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (0.21.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.local/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.14) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml<0.19.0,>=0.17.28 in ./.local/lib/python3.10/site-packages (from hyperpyyaml->speechbrain==0.5.14) (0.18.17)\n",
      "Requirement already satisfied: idna in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (1.0.9)\n",
      "Requirement already satisfied: anyio in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (2026.1.4)\n",
      "Requirement already satisfied: h11>=0.16 in ./.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (0.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.15 in ./.local/lib/python3.10/site-packages (from ruamel.yaml<0.19.0,>=0.17.28->hyperpyyaml->speechbrain==0.5.14) (0.2.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.local/lib/python3.10/site-packages (from typer-slim->huggingface-hub->speechbrain==0.5.14) (8.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub->speechbrain==0.5.14) (1.3.1)\n",
      "Requirement already satisfied: audiomentations==0.33.0 in ./.local/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in ./.local/lib/python3.10/site-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.local/lib/python3.10/site-packages (from audiomentations==0.33.0) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations==0.33.0) (1.15.3)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in ./.local/lib/python3.10/site-packages (from audiomentations==0.33.0) (0.10.2.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.5.3)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.63.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.15.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.local/lib/python3.10/site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.1.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in ./.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.46.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2026.1.4)\n",
      "Requirement already satisfied: torch-audiomentations==0.11.0 in ./.local/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in ./.local/lib/python3.10/site-packages (from torch-audiomentations==0.11.0) (1.2.5)\n",
      "Requirement already satisfied: torch>=1.7.0 in ./.local/lib/python3.10/site-packages (from torch-audiomentations==0.11.0) (2.0.1)\n",
      "Requirement already satisfied: librosa>=0.6.0 in ./.local/lib/python3.10/site-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
      "Requirement already satisfied: torchaudio>=0.7.0 in ./.local/lib/python3.10/site-packages (from torch-audiomentations==0.11.0) (2.0.2)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in ./.local/lib/python3.10/site-packages (from torch-audiomentations==0.11.0) (0.2.7)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.15.3)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.7.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.63.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.15.0)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (5.2.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.local/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.14.3)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.14.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.7.4.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.7.99)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.6)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.20.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.10/site-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.7.101)\n",
      "Requirement already satisfied: wheel in ./.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->torch-audiomentations==0.11.0) (0.45.1)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->torch-audiomentations==0.11.0) (80.9.0)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->torch-audiomentations==0.11.0) (4.2.1)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->torch-audiomentations==0.11.0) (18.1.8)\n",
      "Requirement already satisfied: primePy>=1.3 in ./.local/lib/python3.10/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (1.3)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.local/lib/python3.10/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in ./.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.46.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.5)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2026.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.11)\n",
      "Requirement already satisfied: acoustics==0.2.6 in ./.local/lib/python3.10/site-packages (0.2.6)\n",
      "Requirement already satisfied: numpy>=1.8 in ./.local/lib/python3.10/site-packages (from acoustics==0.2.6) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.15 in ./.local/lib/python3.10/site-packages (from acoustics==0.2.6) (2.3.3)\n",
      "Requirement already satisfied: tabulate in ./.local/lib/python3.10/site-packages (from acoustics==0.2.6) (0.9.0)\n",
      "Requirement already satisfied: six>=1.4.1 in ./.local/lib/python3.10/site-packages (from acoustics==0.2.6) (1.17.0)\n",
      "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from acoustics==0.2.6) (1.15.3)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from acoustics==0.2.6) (3.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.15->acoustics==0.2.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas>=0.15->acoustics==0.2.6) (2025.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (3.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->acoustics==0.2.6) (4.61.1)\n",
      "Requirement already satisfied: tensorflow-gpu==2.8.1 in ./.local/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.1) (25.12.19)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (3.4.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (0.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (2.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (1.17.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (0.2.0)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (80.9.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (18.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (2.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (3.15.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.1) (6.33.4)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (4.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.10/site-packages (from tensorflow-gpu==2.8.1) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.1) (0.45.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.1.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.10)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (2.32.5)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (2.47.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (0.4.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (2.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (2026.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (0.6.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.1) (3.3.1)\n",
      "Requirement already satisfied: tensorflow_probability==0.16.0 in ./.local/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (0.7.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.16.0) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (1.26.4)\n",
      "Requirement already satisfied: dm-tree in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (0.1.9)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (3.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (1.17.0)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from tensorflow_probability==0.16.0) (2.3.1)\n",
      "Requirement already satisfied: attrs>=18.2.0 in ./.local/lib/python3.10/site-packages (from dm-tree->tensorflow_probability==0.16.0) (25.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in ./.local/lib/python3.10/site-packages (from dm-tree->tensorflow_probability==0.16.0) (2.0.1)\n",
      "Requirement already satisfied: onnx_tf==1.10.0 in ./.local/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: onnx>=1.10.2 in ./.local/lib/python3.10/site-packages (from onnx_tf==1.10.0) (1.20.1)\n",
      "Requirement already satisfied: tensorflow-addons in ./.local/lib/python3.10/site-packages (from onnx_tf==1.10.0) (0.23.0)\n",
      "Requirement already satisfied: PyYAML in ./.local/lib/python3.10/site-packages (from onnx_tf==1.10.0) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (6.33.4)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (0.5.4)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (4.15.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in ./.local/lib/python3.10/site-packages (from tensorflow-addons->onnx_tf==1.10.0) (2.13.3)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow-addons->onnx_tf==1.10.0) (25.0)\n",
      "Requirement already satisfied: pronouncing==0.2.0 in ./.local/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in ./.local/lib/python3.10/site-packages (from pronouncing==0.2.0) (1.1.3)\n",
      "Requirement already satisfied: importlib-resources>=5 in ./.local/lib/python3.10/site-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=5 in ./.local/lib/python3.10/site-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.local/lib/python3.10/site-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.23.0)\n",
      "Collecting datasets<4.0\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Using cached pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "Collecting requests>=2.32.2\n",
      "  Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Using cached huggingface_hub-1.3.2-py3-none-any.whl (534 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "Collecting shellingham\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting typing-extensions>=4.1.0\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting typer-slim\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting h11>=0.16\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting click>=8.0.0\n",
      "  Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Using cached exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, shellingham, pyyaml, pyarrow, propcache, packaging, numpy, idna, hf-xet, h11, fsspec, frozenlist, filelock, dill, click, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, typer-slim, requests, python-dateutil, multiprocess, multidict, httpcore, exceptiongroup, aiosignal, yarl, pandas, anyio, httpx, aiohttp, huggingface-hub, datasets\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2025.2\n",
      "    Uninstalling pytz-2025.2:\n",
      "      Successfully uninstalled pytz-2025.2\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 3.6.0\n",
      "    Uninstalling xxhash-3.6.0:\n",
      "      Successfully uninstalled xxhash-3.6.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.6.3\n",
      "    Uninstalling urllib3-2.6.3:\n",
      "      Successfully uninstalled urllib3-2.6.3\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2025.3\n",
      "    Uninstalling tzdata-2025.3:\n",
      "      Successfully uninstalled tzdata-2025.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: shellingham\n",
      "    Found existing installation: shellingham 1.5.4\n",
      "    Uninstalling shellingham-1.5.4:\n",
      "      Successfully uninstalled shellingham-1.5.4\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.3\n",
      "    Uninstalling PyYAML-6.0.3:\n",
      "      Successfully uninstalled PyYAML-6.0.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "  Attempting uninstall: propcache\n",
      "    Found existing installation: propcache 0.4.1\n",
      "    Uninstalling propcache-0.4.1:\n",
      "      Successfully uninstalled propcache-0.4.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.11\n",
      "    Uninstalling idna-3.11:\n",
      "      Successfully uninstalled idna-3.11\n",
      "  Attempting uninstall: hf-xet\n",
      "    Found existing installation: hf-xet 1.2.0\n",
      "    Uninstalling hf-xet-1.2.0:\n",
      "      Successfully uninstalled hf-xet-1.2.0\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.16.0\n",
      "    Uninstalling h11-0.16.0:\n",
      "      Successfully uninstalled h11-0.16.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.8.0\n",
      "    Uninstalling frozenlist-1.8.0:\n",
      "      Successfully uninstalled frozenlist-1.8.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.20.3\n",
      "    Uninstalling filelock-3.20.3:\n",
      "      Successfully uninstalled filelock-3.20.3\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.3.1\n",
      "    Uninstalling click-8.3.1:\n",
      "      Successfully uninstalled click-8.3.1\n",
      "  Attempting uninstall: charset_normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.4\n",
      "    Uninstalling charset-normalizer-3.4.4:\n",
      "      Successfully uninstalled charset-normalizer-3.4.4\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2026.1.4\n",
      "    Uninstalling certifi-2026.1.4:\n",
      "      Successfully uninstalled certifi-2026.1.4\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.4.0\n",
      "    Uninstalling attrs-25.4.0:\n",
      "      Successfully uninstalled attrs-25.4.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.6.1\n",
      "    Uninstalling aiohappyeyeballs-2.6.1:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
      "  Attempting uninstall: typer-slim\n",
      "    Found existing installation: typer-slim 0.21.1\n",
      "    Uninstalling typer-slim-0.21.1:\n",
      "      Successfully uninstalled typer-slim-0.21.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.5\n",
      "    Uninstalling requests-2.32.5:\n",
      "      Successfully uninstalled requests-2.32.5\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.7.0\n",
      "    Uninstalling multidict-6.7.0:\n",
      "      Successfully uninstalled multidict-6.7.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.9\n",
      "    Uninstalling httpcore-1.0.9:\n",
      "      Successfully uninstalled httpcore-1.0.9\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.3.1\n",
      "    Uninstalling exceptiongroup-1.3.1:\n",
      "      Successfully uninstalled exceptiongroup-1.3.1\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.4.0\n",
      "    Uninstalling aiosignal-1.4.0:\n",
      "      Successfully uninstalled aiosignal-1.4.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.22.0\n",
      "    Uninstalling yarl-1.22.0:\n",
      "      Successfully uninstalled yarl-1.22.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.3\n",
      "    Uninstalling pandas-2.3.3:\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.12.1\n",
      "    Uninstalling anyio-4.12.1:\n",
      "      Successfully uninstalled anyio-4.12.1\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "\u001b[33m  WARNING: The script httpx is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.13.3\n",
      "    Uninstalling aiohttp-3.13.3:\n",
      "      Successfully uninstalled aiohttp-3.13.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.3.2\n",
      "    Uninstalling huggingface_hub-1.3.2:\n",
      "      Successfully uninstalled huggingface_hub-1.3.2\n",
      "\u001b[33m  WARNING: The scripts hf and tiny-agents are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.6.0\n",
      "    Uninstalling datasets-3.6.0:\n",
      "      Successfully uninstalled datasets-3.6.0\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.3.1 datasets-3.6.0 dill-0.3.8 exceptiongroup-1.3.1 filelock-3.20.3 frozenlist-1.8.0 fsspec-2025.3.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.3.2 idna-3.11 multidict-6.7.0 multiprocess-0.70.16 numpy-2.2.6 packaging-25.0 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 shellingham-1.5.4 six-1.17.0 tqdm-4.67.1 typer-slim-0.21.1 typing-extensions-4.15.0 tzdata-2025.3 urllib3-2.6.3 xxhash-3.6.0 yarl-1.22.0\n",
      "Requirement already satisfied: deep-phonemizer==0.0.19 in ./.local/lib/python3.10/site-packages (0.0.19)\n",
      "Requirement already satisfied: torch>=1.2.0 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2022.12.7 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (2026.1.4)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (80.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (6.0.3)\n",
      "Requirement already satisfied: tensorboard in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (2.8.0)\n",
      "Requirement already satisfied: wheel>=0.38.0 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (0.45.1)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in ./.local/lib/python3.10/site-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.7.101)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.6)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.4.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.20.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.7.99)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.7.99)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.2.0->deep-phonemizer==0.0.19) (4.2.1)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.2.0->deep-phonemizer==0.0.19) (18.1.8)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (3.1.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (2.2.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (0.4.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (6.33.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (2.3.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (3.10)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (2.47.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (1.76.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard->deep-phonemizer==0.0.19) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer==0.0.19) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer==0.0.19) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->deep-phonemizer==0.0.19) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer==0.0.19) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer==0.0.19) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer==0.0.19) (3.11)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard->deep-phonemizer==0.0.19) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deep-phonemizer==0.0.19) (0.6.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->deep-phonemizer==0.0.19) (3.3.1)\n",
      "Requirement already satisfied: ipywidgets in ./.local/lib/python3.10/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.38.0)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.local/lib/python3.10/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.local/lib/python3.10/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: soundfile in ./.local/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in ./.local/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread in ./.local/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from soundfile) (2.2.6)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.local/lib/python3.10/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.3)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.local/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.10/site-packages (from librosa) (0.63.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.local/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.local/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.local/lib/python3.10/site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in ./.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.46.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2026.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.6.3)\n",
      "Collecting torchaudio<2.1.0\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting torch==2.0.1\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting lit\n",
      "  Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Collecting cmake\n",
      "  Using cached cmake-4.2.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (28.9 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, lit, wheel, typing-extensions, sympy, setuptools, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, filelock, cmake, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: lit\n",
      "    Found existing installation: lit 18.1.8\n",
      "    Uninstalling lit-18.1.8:\n",
      "      Successfully uninstalled lit-18.1.8\n",
      "\u001b[33m  WARNING: The script lit is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.45.1\n",
      "    Uninstalling wheel-0.45.1:\n",
      "      Successfully uninstalled wheel-0.45.1\n",
      "\u001b[33m  WARNING: The script wheel is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 80.9.0\n",
      "    Uninstalling setuptools-80.9.0:\n",
      "      Successfully uninstalled setuptools-80.9.0\n",
      "  Attempting uninstall: nvidia-nccl-cu11\n",
      "    Found existing installation: nvidia-nccl-cu11 2.14.3\n",
      "    Uninstalling nvidia-nccl-cu11-2.14.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu11-2.14.3\n",
      "  Attempting uninstall: nvidia-cufft-cu11\n",
      "    Found existing installation: nvidia-cufft-cu11 10.9.0.58\n",
      "    Uninstalling nvidia-cufft-cu11-10.9.0.58:\n",
      "      Successfully uninstalled nvidia-cufft-cu11-10.9.0.58\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.3\n",
      "    Uninstalling MarkupSafe-3.0.3:\n",
      "      Successfully uninstalled MarkupSafe-3.0.3\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.20.3\n",
      "    Uninstalling filelock-3.20.3:\n",
      "      Successfully uninstalled filelock-3.20.3\n",
      "  Attempting uninstall: cmake\n",
      "    Found existing installation: cmake 4.2.1\n",
      "    Uninstalling cmake-4.2.1:\n",
      "      Successfully uninstalled cmake-4.2.1\n",
      "\u001b[33m  WARNING: The scripts ccmake, cmake, cpack and ctest are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: nvidia-nvtx-cu11\n",
      "    Found existing installation: nvidia-nvtx-cu11 11.7.91\n",
      "    Uninstalling nvidia-nvtx-cu11-11.7.91:\n",
      "      Successfully uninstalled nvidia-nvtx-cu11-11.7.91\n",
      "  Attempting uninstall: nvidia-cusparse-cu11\n",
      "    Found existing installation: nvidia-cusparse-cu11 11.7.4.91\n",
      "    Uninstalling nvidia-cusparse-cu11-11.7.4.91:\n",
      "      Successfully uninstalled nvidia-cusparse-cu11-11.7.4.91\n",
      "  Attempting uninstall: nvidia-curand-cu11\n",
      "    Found existing installation: nvidia-curand-cu11 10.2.10.91\n",
      "    Uninstalling nvidia-curand-cu11-10.2.10.91:\n",
      "      Successfully uninstalled nvidia-curand-cu11-10.2.10.91\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
      "    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n",
      "    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
      "    Found existing installation: nvidia-cuda-cupti-cu11 11.7.101\n",
      "    Uninstalling nvidia-cuda-cupti-cu11-11.7.101:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.7.101\n",
      "  Attempting uninstall: nvidia-cublas-cu11\n",
      "    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
      "    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
      "      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "  Attempting uninstall: nvidia-cusolver-cu11\n",
      "    Found existing installation: nvidia-cusolver-cu11 11.4.0.1\n",
      "    Uninstalling nvidia-cusolver-cu11-11.4.0.1:\n",
      "      Successfully uninstalled nvidia-cusolver-cu11-11.4.0.1\n",
      "  Attempting uninstall: nvidia-cudnn-cu11\n",
      "    Found existing installation: nvidia-cudnn-cu11 8.5.0.96\n",
      "    Uninstalling nvidia-cudnn-cu11-8.5.0.96:\n",
      "      Successfully uninstalled nvidia-cudnn-cu11-8.5.0.96\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.0.2\n",
      "    Uninstalling torchaudio-2.0.2:\n",
      "      Successfully uninstalled torchaudio-2.0.2\n",
      "Successfully installed MarkupSafe-3.0.3 cmake-4.2.1 filelock-3.20.3 jinja2-3.1.6 lit-18.1.8 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 setuptools-80.9.0 sympy-1.14.0 torch-2.0.1 torchaudio-2.0.2 triton-2.0.0 typing-extensions-4.15.0 wheel-0.45.1\n",
      "--2026-01-18 08:10:38--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
      "140.82.116.4thub.com (github.com)... \n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "302 Foundest sent, awaiting response... \n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A44%3A47Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A44%3A30Z&ske=2026-01-18T08%3A44%3A47Z&sks=b&skv=2018-11-09&sig=7AGwwXom%2Bcf19itV7Ju9kPCFujE9QdP%2F%2FZM7lau2fnE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDEzOCwibmJmIjoxNzY4NzIzODM4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.NxnSfpKxRxhsy-lqLni90K7VYS5JufyOTyqYhzkkhA8&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
      "--2026-01-18 08:10:38--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A44%3A47Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A44%3A30Z&ske=2026-01-18T08%3A44%3A47Z&sks=b&skv=2018-11-09&sig=7AGwwXom%2Bcf19itV7Ju9kPCFujE9QdP%2F%2FZM7lau2fnE%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDEzOCwibmJmIjoxNzY4NzIzODM4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.NxnSfpKxRxhsy-lqLni90K7VYS5JufyOTyqYhzkkhA8&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
      "185.199.110.133, 185.199.111.133, 185.199.109.133, ...e-assets.githubusercontent.com)... \n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 1326578 (1.3M) [application/octet-stream]\n",
      "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
      "\n",
      "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2026-01-18 08:10:39 (21.0 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
      "\n",
      "--2026-01-18 08:10:39--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "302 Foundest sent, awaiting response... \n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A45%3A22Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A44%3A54Z&ske=2026-01-18T08%3A45%3A22Z&sks=b&skv=2018-11-09&sig=fC%2F3nqTGbDK1Ya67tb6%2Fx9YJIdReBD7Le3UI5OfA6RU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDEzOSwibmJmIjoxNzY4NzIzODM5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.xSYjD_ro-DR6vKY05IlhwoXIhq68SxMLAyUNoBZHteE&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
      "--2026-01-18 08:10:39--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A45%3A22Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A44%3A54Z&ske=2026-01-18T08%3A45%3A22Z&sks=b&skv=2018-11-09&sig=fC%2F3nqTGbDK1Ya67tb6%2Fx9YJIdReBD7Le3UI5OfA6RU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDEzOSwibmJmIjoxNzY4NzIzODM5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.xSYjD_ro-DR6vKY05IlhwoXIhq68SxMLAyUNoBZHteE&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1330312 (1.3M) [application/octet-stream]\n",
      "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
      "\n",
      "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2026-01-18 08:10:39 (22.2 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
      "\n",
      "--2026-01-18 08:10:39--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A52%3A50Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A52%3A15Z&ske=2026-01-18T08%3A52%3A50Z&sks=b&skv=2018-11-09&sig=9ijDba6zWQPCSfw4jwoeeZZXGT%2Fm6N4PCgs5vGVeSiM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDE0MCwibmJmIjoxNzY4NzIzODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lMmv7Kad88Yf6vKpbRF48ZK-h16-ThkZHTVzm8o1X5c&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
      "--2026-01-18 08:10:40--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T08%3A52%3A50Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T07%3A52%3A15Z&ske=2026-01-18T08%3A52%3A50Z&sks=b&skv=2018-11-09&sig=9ijDba6zWQPCSfw4jwoeeZZXGT%2Fm6N4PCgs5vGVeSiM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDE0MCwibmJmIjoxNzY4NzIzODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lMmv7Kad88Yf6vKpbRF48ZK-h16-ThkZHTVzm8o1X5c&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
      "185.199.111.133, 185.199.109.133, 185.199.110.133, ...e-assets.githubusercontent.com)... \n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 1087958 (1.0M) [application/octet-stream]\n",
      "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
      "\n",
      "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2026-01-18 08:10:40 (16.9 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
      "\n",
      "--2026-01-18 08:10:40--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T09%3A01%3A08Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T08%3A00%3A20Z&ske=2026-01-18T09%3A01%3A08Z&sks=b&skv=2018-11-09&sig=z%2FlHftg8ul1PivqBjv5pbv%2BoxCSksm955en93YNRRUI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDE0MCwibmJmIjoxNzY4NzIzODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lMmv7Kad88Yf6vKpbRF48ZK-h16-ThkZHTVzm8o1X5c&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
      "--2026-01-18 08:10:40--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-18T09%3A01%3A08Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-18T08%3A00%3A20Z&ske=2026-01-18T09%3A01%3A08Z&sks=b&skv=2018-11-09&sig=z%2FlHftg8ul1PivqBjv5pbv%2BoxCSksm955en93YNRRUI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODcyNDE0MCwibmJmIjoxNzY4NzIzODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lMmv7Kad88Yf6vKpbRF48ZK-h16-ThkZHTVzm8o1X5c&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1092516 (1.0M) [application/octet-stream]\n",
      "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
      "\n",
      "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2026-01-18 08:10:40 (11.6 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Environment setup\n",
    "\n",
    "# install piper-sample-generator (currently only supports linux systems)\n",
    "!rm -rf piper-sample-generator  # Clean up if exists\n",
    "!git clone https://github.com/rhasspy/piper-sample-generator\n",
    "!wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
    "!pip install --user piper-phonemize\n",
    "!pip install --user webrtcvad\n",
    "\n",
    "# install openwakeword - use normal install, not editable\n",
    "!rm -rf openwakeword  # Clean up if exists\n",
    "!git clone https://github.com/celesrenata/jupyter-training openwakeword\n",
    "# Skip the editable install - openwakeword is already in the image\n",
    "# If you need to modify openwakeword code, edit it directly in ./openwakeword/\n",
    "\n",
    "# install other dependencies with compatible versions\n",
    "!pip install --user 'numpy<2.0'\n",
    "!pip install --user 'pyarrow<15.0.0'\n",
    "!pip install --user mutagen==1.47.0\n",
    "!pip install --user torchinfo==1.8.0\n",
    "!pip install --user torchmetrics==1.2.0\n",
    "!pip install --user speechbrain==0.5.14\n",
    "!pip install --user audiomentations==0.33.0\n",
    "!pip install --user torch-audiomentations==0.11.0\n",
    "!pip install --user acoustics==0.2.6\n",
    "!pip install --user tensorflow-gpu==2.8.1\n",
    "!pip install --user tensorflow_probability==0.16.0\n",
    "!pip install --user onnx_tf==1.10.0\n",
    "!pip install --user pronouncing==0.2.0\n",
    "!pip install --user 'datasets<4.0' --force-reinstall\n",
    "!pip install --user deep-phonemizer==0.0.19\n",
    "!pip install --user ipywidgets\n",
    "!pip install --user soundfile librosa audioread\n",
    "!pip install --user 'torchaudio<2.1.0' --force-reinstall\n",
    "\n",
    "# Download required models\n",
    "import os\n",
    "os.makedirs(\"./openwakeword/openwakeword/resources/models\", exist_ok=True)\n",
    "!wget -nc https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
    "!wget -nc https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
    "!wget -nc https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
    "!wget -nc https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c1056e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T13:42:01.183840Z",
     "start_time": "2023-09-04T13:41:59.752153Z"
    },
    "id": "d4c1056e"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/.local/lib/python3.10/site-packages')\n",
    "\n",
    "# Patch datasets before importing\n",
    "import datasets.features.audio as audio_module\n",
    "audio_module.TORCHCODEC_AVAILABLE = False\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import yaml\n",
    "import datasets\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "from tqdm import tqdm\n",
    "import soundfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7a05a",
   "metadata": {
    "id": "e9d7a05a"
   },
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f75cc",
   "metadata": {
    "id": "c52f75cc"
   },
   "source": [
    "When training new openWakeWord models using the automated procedure, four specific types of data are required:\n",
    "\n",
    "1) Synthetic examples of the target word/phrase generated with text-to-speech models\n",
    "\n",
    "2) Synthetic examples of adversarial words/phrases generated with text-to-speech models\n",
    "\n",
    "3) Room impulse reponses and noise/background audio data to augment the synthetic examples and make them more realistic\n",
    "\n",
    "4) Generic \"negative\" audio data that is very unlikely to contain examples of the target word/phrase in the context where the model should detect it. This data can be the original audio data, or precomputed openWakeWord features ready for model training.\n",
    "\n",
    "5) Validation data to use for early-stopping when training the model.\n",
    "\n",
    "For the purposes of this notebook, all five of these sources will either be generated manually or can be obtained from HuggingFace thanks to their excellent `datasets` library and extremely generous hosting policy. Also note that while only a portion of some datasets are downloaded, for the best possible performance it is recommended to download the entire dataset and keep a local copy for future training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25a93b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T01:07:17.746749Z",
     "start_time": "2023-09-04T01:07:17.740846Z"
    },
    "id": "d25a93b1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ae6d9367004bf98337c31f75539a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2472/1901200139.py\", line 8, in <module>\n",
      "    rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/load.py\", line 2081, in load_dataset\n",
      "    return builder_instance.as_streaming_dataset(split=split)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/builder.py\", line 1275, in as_streaming_dataset\n",
      "    datasets = map_nested(\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py\", line 494, in map_nested\n",
      "    mapped = function(data_struct)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/builder.py\", line 1291, in _as_streaming_dataset_single\n",
      "    return IterableDataset(\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py\", line 1974, in __init__\n",
      "    self._epoch: Union[int, \"torch.Tensor\"] = _maybe_share_with_torch_persistent_workers(0)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py\", line 1942, in _maybe_share_with_torch_persistent_workers\n",
      "    return torch.tensor(value).share_memory_()\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py:1942: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  return torch.tensor(value).share_memory_()\n",
      "270it [00:57,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download room impulse responses collected by MIT\n",
    "# https://mcdermottlab.mit.edu/Reverb/IR_Survey.html\n",
    "\n",
    "output_dir = \"./mit_rirs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
    "\n",
    "# Save clips to 16-bit PCM wav files\n",
    "for row in tqdm(rir_dataset):\n",
    "    audio_data = row['audio']\n",
    "    name = audio_data['path'].split('/')[-1]\n",
    "    scipy.io.wavfile.write(os.path.join(output_dir, name), audio_data['sampling_rate'], (audio_data['array']*32767).astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0e178b",
   "metadata": {
    "id": "2c0e178b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AudioSet tar file...\n",
      "Extracting audioset/bal_train09.tar ...\n",
      "Found 685 AudioSet FLACs. Converting to 16k wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to 16000 Hz wav: 100%|██████████| 685/685 [00:21<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioSet: wrote 685 wav files to audioset_16k\n",
      "FMA zip already exists: fma_download/fma_small.zip\n",
      "Extracting fma_download/fma_small.zip ...\n",
      "Found 8000 FMA MP3s. Converting ~1 hour(s) (~120 files) to 16k wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (3360) too large for available bit count (3240)\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (3328) too large for available bit count (3240)\n",
      "Converting to 16000 Hz wav: 100%|██████████| 120/120 [00:12<00:00,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMA: wrote 120 wav files to fma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "from huggingface_hub import hf_hub_download\n",
    "import requests\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "# Do NOT hardcode tokens. Export it instead:\n",
    "#   export HF_TOKEN=\"hf_....\"\n",
    "HF_TOKEN = \"\"\n",
    "AUDISET_REPO = \"agkphysics/AudioSet\"\n",
    "AUDISET_FILENAME = \"bal_train09.tar\"\n",
    "AUDISET_REVISION = \"196c0900867eff791b8f4d4be57db277e9a5b131\"\n",
    "\n",
    "# FMA is NOT stored as a zip in the HF dataset repo path you tried.\n",
    "# Download from the official host instead:\n",
    "FMA_ZIP_URL = \"https://os.unil.cloud.switch.ch/fma/fma_small.zip\"\n",
    "\n",
    "AUDISET_DIR = Path(\"./audioset\")\n",
    "AUDISET_16K_DIR = Path(\"./audioset_16k\")\n",
    "\n",
    "FMA_DL_DIR = Path(\"./fma_download\")\n",
    "FMA_OUT_DIR = Path(\"./fma\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "def ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_tar(tar_path: Path, dst_dir: Path) -> None:\n",
    "    ensure_dir(dst_dir)\n",
    "    with tarfile.open(tar_path, \"r:*\") as tf:\n",
    "        tf.extractall(dst_dir)\n",
    "\n",
    "\n",
    "def extract_zip(zip_path: Path, dst_dir: Path) -> None:\n",
    "    ensure_dir(dst_dir)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(dst_dir)\n",
    "\n",
    "\n",
    "def download_file(url: str, out_path: Path, chunk_size: int = 1024 * 1024) -> Path:\n",
    "    ensure_dir(out_path.parent)\n",
    "    with requests.get(url, stream=True, timeout=None) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"content-length\", 0))\n",
    "        with open(out_path, \"wb\") as f, tqdm(\n",
    "            total=total, unit=\"B\", unit_scale=True, desc=out_path.name\n",
    "        ) as pbar:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def convert_audio_files_to_16k_wav(\n",
    "    input_paths,\n",
    "    output_dir: Path,\n",
    "    sampling_rate: int = 16000,\n",
    "    limit_files: int | None = None,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Uses HuggingFace datasets Audio feature to decode + resample.\n",
    "    Requires ffmpeg for mp3/flac decoding in most environments.\n",
    "    \"\"\"\n",
    "    ensure_dir(output_dir)\n",
    "\n",
    "    input_paths = list(map(str, input_paths))\n",
    "    if not input_paths:\n",
    "        return 0\n",
    "\n",
    "    if limit_files is not None:\n",
    "        input_paths = input_paths[:limit_files]\n",
    "\n",
    "    ds = datasets.Dataset.from_dict({\"audio\": input_paths})\n",
    "    ds = ds.cast_column(\"audio\", datasets.Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "    written = 0\n",
    "    for row in tqdm(ds, total=len(ds), desc=f\"Converting to {sampling_rate} Hz wav\"):\n",
    "        src_path = Path(row[\"audio\"][\"path\"])\n",
    "        arr = np.asarray(row[\"audio\"][\"array\"], dtype=np.float32)\n",
    "\n",
    "        arr = np.clip(arr, -1.0, 1.0)\n",
    "        pcm16 = (arr * 32767.0).astype(np.int16)\n",
    "\n",
    "        out_path = output_dir / src_path.with_suffix(\".wav\").name\n",
    "        scipy.io.wavfile.write(out_path, sampling_rate, pcm16)\n",
    "        written += 1\n",
    "\n",
    "    return written\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# AUDIOSET\n",
    "# -------------------------\n",
    "ensure_dir(AUDISET_DIR)\n",
    "print(\"Downloading AudioSet tar file...\")\n",
    "audioset_tar_path = hf_hub_download(\n",
    "    repo_id=AUDISET_REPO,\n",
    "    repo_type=\"dataset\",\n",
    "    filename=AUDISET_FILENAME,\n",
    "    token=HF_TOKEN,\n",
    "    revision=AUDISET_REVISION,\n",
    "    local_dir=str(AUDISET_DIR),\n",
    "    resume_download=True,\n",
    ")\n",
    "\n",
    "audioset_tar_path = Path(audioset_tar_path)\n",
    "print(f\"Extracting {audioset_tar_path} ...\")\n",
    "extract_tar(audioset_tar_path, AUDISET_DIR)\n",
    "\n",
    "audioset_flacs = list(AUDISET_DIR.glob(\"**/*.flac\"))\n",
    "if not audioset_flacs:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No .flac files found under {AUDISET_DIR}. \"\n",
    "        \"Inspect the extracted folder structure to update the glob.\"\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(audioset_flacs)} AudioSet FLACs. Converting to 16k wav...\")\n",
    "n_written = convert_audio_files_to_16k_wav(audioset_flacs, AUDISET_16K_DIR, sampling_rate=16000)\n",
    "print(f\"AudioSet: wrote {n_written} wav files to {AUDISET_16K_DIR}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# FMA (official host)\n",
    "# -------------------------\n",
    "ensure_dir(FMA_DL_DIR)\n",
    "ensure_dir(FMA_OUT_DIR)\n",
    "\n",
    "fma_zip_path = FMA_DL_DIR / \"fma_small.zip\"\n",
    "if not fma_zip_path.exists():\n",
    "    print(\"Downloading FMA zip file from official host...\")\n",
    "    download_file(FMA_ZIP_URL, fma_zip_path)\n",
    "else:\n",
    "    print(f\"FMA zip already exists: {fma_zip_path}\")\n",
    "\n",
    "print(f\"Extracting {fma_zip_path} ...\")\n",
    "extract_zip(fma_zip_path, FMA_DL_DIR)\n",
    "\n",
    "fma_mp3s = list(FMA_DL_DIR.glob(\"**/*.mp3\"))\n",
    "if not fma_mp3s:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No .mp3 files found under {FMA_DL_DIR}. \"\n",
    "        \"Inspect the extracted folder structure to update the glob.\"\n",
    "    )\n",
    "\n",
    "# Optional: limit by hours (rough heuristic)\n",
    "n_hours = 1\n",
    "approx_track_seconds = 30\n",
    "approx_files = int(n_hours * 3600 / approx_track_seconds)\n",
    "\n",
    "print(f\"Found {len(fma_mp3s)} FMA MP3s. Converting ~{n_hours} hour(s) (~{approx_files} files) to 16k wav...\")\n",
    "n_written = convert_audio_files_to_16k_wav(\n",
    "    fma_mp3s,\n",
    "    FMA_OUT_DIR,\n",
    "    sampling_rate=16000,\n",
    "    limit_files=approx_files,\n",
    ")\n",
    "print(f\"FMA: wrote {n_written} wav files to {FMA_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01ec467",
   "metadata": {
    "id": "d01ec467"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validation_set_features.npy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download pre-computed openWakeWord features for training and validation\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "HF_TOKEN = \"\"  # Set to your token string or leave as None\n",
    "\n",
    "# training set (~2,000 hours from the ACAV100M Dataset)\n",
    "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
    "hf_hub_download(\n",
    "    repo_id=\"davidscripka/openwakeword_features\",\n",
    "    filename=\"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\",\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN,\n",
    "    local_dir=\".\"\n",
    ")\n",
    "\n",
    "# validation set for false positive rate estimation (~11 hours)\n",
    "hf_hub_download(\n",
    "    repo_id=\"davidscripka/openwakeword_features\",\n",
    "    filename=\"validation_set_features.npy\",\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN,\n",
    "    local_dir=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe82647",
   "metadata": {
    "id": "cfe82647"
   },
   "source": [
    "# Define Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e71329",
   "metadata": {
    "id": "b2e71329"
   },
   "source": [
    "For automated model training openWakeWord uses a specially designed training script and a [YAML](https://yaml.org/) configuration file that defines all of the information required for training a new wake word/phrase detection model.\n",
    "\n",
    "It is strongly recommended that you review [the example config file](../examples/custom_model.yml), as each value is fully documented there. For the purposes of this notebook, we'll read in the YAML file to modify certain configuration parameters before saving a new YAML file for training our example model. Specifically:\n",
    "\n",
    "- We'll train a detection model for the phrase \"hey sebastian\"\n",
    "- We'll only generate 5,000 positive and negative examples (to save on time for this example)\n",
    "- We'll only generate 1,000 validation positive and negative examples for early stopping (again to save time)\n",
    "- The model will only be trained for 10,000 steps (larger datasets will benefit from longer training)\n",
    "- We'll reduce the target metrics to account for the small dataset size and limited training.\n",
    "\n",
    "On the topic of target metrics, there are *not* specific guidelines about what these metrics should be in practice, and you will need to conduct testing in your target deployment environment to establish good thresholds. However, from very limited testing the default values in the config file (accuracy >= 0.7, recall >= 0.5, false-positive rate <= 0.2 per hour) seem to produce models with reasonable performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0b6e4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T18:11:33.893397Z",
     "start_time": "2023-09-04T18:11:33.878938Z"
    },
    "id": "fb0b6e4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'my_model',\n",
       " 'target_phrase': ['hey jarvis'],\n",
       " 'custom_negative_phrases': [],\n",
       " 'n_samples': 10000,\n",
       " 'n_samples_val': 2000,\n",
       " 'tts_batch_size': 50,\n",
       " 'augmentation_batch_size': 16,\n",
       " 'piper_sample_generator_path': './piper-sample-generator',\n",
       " 'output_dir': './my_custom_model',\n",
       " 'rir_paths': ['./mit_rirs'],\n",
       " 'background_paths': ['./background_clips'],\n",
       " 'background_paths_duplication_rate': [1],\n",
       " 'false_positive_validation_data_path': './validation_set_features.npy',\n",
       " 'augmentation_rounds': 1,\n",
       " 'feature_data_files': {'ACAV100M_sample': './openwakeword_features_ACAV100M_2000_hrs_16bit.npy'},\n",
       " 'batch_n_per_class': {'ACAV100M_sample': 1024,\n",
       "  'adversarial_negative': 50,\n",
       "  'positive': 50},\n",
       " 'model_type': 'dnn',\n",
       " 'layer_size': 32,\n",
       " 'steps': 50000,\n",
       " 'max_negative_weight': 1500,\n",
       " 'target_false_positives_per_hour': 0.2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load default YAML config file for training\n",
    "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482cf2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:07:00.859210Z",
     "start_time": "2023-09-04T15:07:00.841472Z"
    },
    "id": "482cf2d0"
   },
   "outputs": [],
   "source": [
    "config[\"target_phrase\"] = [\"nixberry\"]\n",
    "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
    "config[\"n_samples\"] = 5000  # Less is better for quality\n",
    "config[\"n_samples_val\"] = 1000\n",
    "config[\"steps\"] = 10000\n",
    "config[\"target_false_positives_per_hour\"] = 1.0  # Allow more false positives for better recall\n",
    "config[\"max_negative_weight\"] = 500  # Reduce from 1500 to be less aggressive\n",
    "config[\"piper_model_path\"] = \"./piper-sample-generator/models/en_US-libritts_r-medium.pt\"\n",
    "config[\"background_paths\"] = ['./audioset_16k', './fma']\n",
    "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
    "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
    "\n",
    "with open('my_model.yaml', 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b2ab0",
   "metadata": {
    "id": "aa6b2ab0"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51202c0",
   "metadata": {
    "id": "a51202c0"
   },
   "source": [
    "With the data downloaded and training configuration set, we can now start training the model. We'll do this in parts to better illustrate the sequence, but you can also execute every step at once for a fully automated process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f01531fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T13:50:08.803326Z",
     "start_time": "2023-09-04T13:50:06.790241Z"
    },
    "id": "f01531fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy<2 in ./.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: piper-tts in ./.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: onnxruntime<2,>=1 in /usr/local/lib/python3.10/dist-packages (from piper-tts) (1.23.2)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from onnxruntime<2,>=1->piper-tts) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1->piper-tts) (15.0.1)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from onnxruntime<2,>=1->piper-tts) (25.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1->piper-tts) (6.33.4)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1->piper-tts) (25.12.19)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1->piper-tts) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->onnxruntime<2,>=1->piper-tts) (1.3.0)\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/pronouncing/__init__.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream\n",
      "torchvision is not available - cannot save figures\n",
      "INFO:root:##################################################\n",
      "Generating positive clips for training\n",
      "##################################################\n",
      "DEBUG:generate_samples:Loading ./piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n",
      "DEBUG:generate_samples:Batch 1/100 complete\n",
      "DEBUG:generate_samples:Batch 2/100 complete\n",
      "DEBUG:generate_samples:Batch 3/100 complete\n",
      "DEBUG:generate_samples:Batch 4/100 complete\n",
      "DEBUG:generate_samples:Batch 5/100 complete\n",
      "DEBUG:generate_samples:Batch 6/100 complete\n",
      "DEBUG:generate_samples:Batch 7/100 complete\n",
      "DEBUG:generate_samples:Batch 8/100 complete\n",
      "DEBUG:generate_samples:Batch 9/100 complete\n",
      "DEBUG:generate_samples:Batch 10/100 complete\n",
      "DEBUG:generate_samples:Batch 11/100 complete\n",
      "DEBUG:generate_samples:Batch 12/100 complete\n",
      "DEBUG:generate_samples:Batch 13/100 complete\n",
      "DEBUG:generate_samples:Batch 14/100 complete\n",
      "DEBUG:generate_samples:Batch 15/100 complete\n",
      "DEBUG:generate_samples:Batch 16/100 complete\n",
      "DEBUG:generate_samples:Batch 17/100 complete\n",
      "DEBUG:generate_samples:Batch 18/100 complete\n",
      "DEBUG:generate_samples:Batch 19/100 complete\n",
      "DEBUG:generate_samples:Batch 20/100 complete\n",
      "DEBUG:generate_samples:Batch 21/100 complete\n",
      "DEBUG:generate_samples:Batch 22/100 complete\n",
      "DEBUG:generate_samples:Batch 23/100 complete\n",
      "DEBUG:generate_samples:Batch 24/100 complete\n",
      "DEBUG:generate_samples:Batch 25/100 complete\n",
      "DEBUG:generate_samples:Batch 26/100 complete\n",
      "DEBUG:generate_samples:Batch 27/100 complete\n",
      "DEBUG:generate_samples:Batch 28/100 complete\n",
      "DEBUG:generate_samples:Batch 29/100 complete\n",
      "DEBUG:generate_samples:Batch 30/100 complete\n",
      "DEBUG:generate_samples:Batch 31/100 complete\n",
      "DEBUG:generate_samples:Batch 32/100 complete\n",
      "DEBUG:generate_samples:Batch 33/100 complete\n",
      "DEBUG:generate_samples:Batch 34/100 complete\n",
      "DEBUG:generate_samples:Batch 35/100 complete\n",
      "DEBUG:generate_samples:Batch 36/100 complete\n",
      "DEBUG:generate_samples:Batch 37/100 complete\n",
      "DEBUG:generate_samples:Batch 38/100 complete\n",
      "DEBUG:generate_samples:Batch 39/100 complete\n",
      "DEBUG:generate_samples:Batch 40/100 complete\n",
      "DEBUG:generate_samples:Batch 41/100 complete\n",
      "DEBUG:generate_samples:Batch 42/100 complete\n",
      "DEBUG:generate_samples:Batch 43/100 complete\n",
      "DEBUG:generate_samples:Batch 44/100 complete\n",
      "DEBUG:generate_samples:Batch 45/100 complete\n",
      "DEBUG:generate_samples:Batch 46/100 complete\n",
      "DEBUG:generate_samples:Batch 47/100 complete\n",
      "DEBUG:generate_samples:Batch 48/100 complete\n",
      "DEBUG:generate_samples:Batch 49/100 complete\n",
      "DEBUG:generate_samples:Batch 50/100 complete\n",
      "DEBUG:generate_samples:Batch 51/100 complete\n",
      "DEBUG:generate_samples:Batch 52/100 complete\n",
      "DEBUG:generate_samples:Batch 53/100 complete\n",
      "DEBUG:generate_samples:Batch 54/100 complete\n",
      "DEBUG:generate_samples:Batch 55/100 complete\n",
      "DEBUG:generate_samples:Batch 56/100 complete\n",
      "DEBUG:generate_samples:Batch 57/100 complete\n",
      "DEBUG:generate_samples:Batch 58/100 complete\n",
      "DEBUG:generate_samples:Batch 59/100 complete\n",
      "DEBUG:generate_samples:Batch 60/100 complete\n",
      "DEBUG:generate_samples:Batch 61/100 complete\n",
      "DEBUG:generate_samples:Batch 62/100 complete\n",
      "DEBUG:generate_samples:Batch 63/100 complete\n",
      "DEBUG:generate_samples:Batch 64/100 complete\n",
      "DEBUG:generate_samples:Batch 65/100 complete\n",
      "DEBUG:generate_samples:Batch 66/100 complete\n",
      "DEBUG:generate_samples:Batch 67/100 complete\n",
      "DEBUG:generate_samples:Batch 68/100 complete\n",
      "DEBUG:generate_samples:Batch 69/100 complete\n",
      "DEBUG:generate_samples:Batch 70/100 complete\n",
      "DEBUG:generate_samples:Batch 71/100 complete\n",
      "DEBUG:generate_samples:Batch 72/100 complete\n",
      "DEBUG:generate_samples:Batch 73/100 complete\n",
      "DEBUG:generate_samples:Batch 74/100 complete\n",
      "DEBUG:generate_samples:Batch 75/100 complete\n",
      "DEBUG:generate_samples:Batch 76/100 complete\n",
      "DEBUG:generate_samples:Batch 77/100 complete\n",
      "DEBUG:generate_samples:Batch 78/100 complete\n",
      "DEBUG:generate_samples:Batch 79/100 complete\n",
      "DEBUG:generate_samples:Batch 80/100 complete\n",
      "DEBUG:generate_samples:Batch 81/100 complete\n",
      "DEBUG:generate_samples:Batch 82/100 complete\n",
      "DEBUG:generate_samples:Batch 83/100 complete\n",
      "DEBUG:generate_samples:Batch 84/100 complete\n",
      "DEBUG:generate_samples:Batch 85/100 complete\n",
      "DEBUG:generate_samples:Batch 86/100 complete\n",
      "DEBUG:generate_samples:Batch 87/100 complete\n",
      "DEBUG:generate_samples:Batch 88/100 complete\n",
      "DEBUG:generate_samples:Batch 89/100 complete\n",
      "DEBUG:generate_samples:Batch 90/100 complete\n",
      "DEBUG:generate_samples:Batch 91/100 complete\n",
      "DEBUG:generate_samples:Batch 92/100 complete\n",
      "DEBUG:generate_samples:Batch 93/100 complete\n",
      "DEBUG:generate_samples:Batch 94/100 complete\n",
      "DEBUG:generate_samples:Batch 95/100 complete\n",
      "DEBUG:generate_samples:Batch 96/100 complete\n",
      "DEBUG:generate_samples:Batch 97/100 complete\n",
      "DEBUG:generate_samples:Batch 98/100 complete\n",
      "DEBUG:generate_samples:Batch 99/100 complete\n",
      "DEBUG:generate_samples:Batch 100/100 complete\n",
      "INFO:generate_samples:Done\n",
      "INFO:root:##################################################\n",
      "Generating positive clips for testing\n",
      "##################################################\n",
      "DEBUG:generate_samples:Loading ./piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n",
      "DEBUG:generate_samples:Batch 1/20 complete\n",
      "DEBUG:generate_samples:Batch 2/20 complete\n",
      "DEBUG:generate_samples:Batch 3/20 complete\n",
      "DEBUG:generate_samples:Batch 4/20 complete\n",
      "DEBUG:generate_samples:Batch 5/20 complete\n",
      "DEBUG:generate_samples:Batch 6/20 complete\n",
      "DEBUG:generate_samples:Batch 7/20 complete\n",
      "DEBUG:generate_samples:Batch 8/20 complete\n",
      "DEBUG:generate_samples:Batch 9/20 complete\n",
      "DEBUG:generate_samples:Batch 10/20 complete\n",
      "DEBUG:generate_samples:Batch 11/20 complete\n",
      "DEBUG:generate_samples:Batch 12/20 complete\n",
      "DEBUG:generate_samples:Batch 13/20 complete\n",
      "DEBUG:generate_samples:Batch 14/20 complete\n",
      "DEBUG:generate_samples:Batch 15/20 complete\n",
      "DEBUG:generate_samples:Batch 16/20 complete\n",
      "DEBUG:generate_samples:Batch 17/20 complete\n",
      "DEBUG:generate_samples:Batch 18/20 complete\n",
      "DEBUG:generate_samples:Batch 19/20 complete\n",
      "DEBUG:generate_samples:Batch 20/20 complete\n",
      "INFO:generate_samples:Done\n",
      "INFO:root:##################################################\n",
      "Generating negative clips for training\n",
      "##################################################\n",
      "DEBUG:dp.phonemizer:Initializing phonemizer with model step 1120000\n",
      "WARNING:root:The word 'nixberry' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
      "WARNING:root:Phones for 'nixberry': [N][IH][K][S][B][EH][R][IY]\n",
      "DEBUG:generate_samples:Loading ./piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n",
      "DEBUG:generate_samples:Batch 1/714 complete\n",
      "DEBUG:generate_samples:Batch 2/714 complete\n",
      "DEBUG:generate_samples:Batch 3/714 complete\n",
      "DEBUG:generate_samples:Batch 4/714 complete\n",
      "DEBUG:generate_samples:Batch 5/714 complete\n",
      "DEBUG:generate_samples:Batch 6/714 complete\n",
      "DEBUG:generate_samples:Batch 7/714 complete\n",
      "DEBUG:generate_samples:Batch 8/714 complete\n",
      "DEBUG:generate_samples:Batch 9/714 complete\n",
      "DEBUG:generate_samples:Batch 10/714 complete\n",
      "DEBUG:generate_samples:Batch 11/714 complete\n",
      "DEBUG:generate_samples:Batch 12/714 complete\n",
      "DEBUG:generate_samples:Batch 13/714 complete\n",
      "DEBUG:generate_samples:Batch 14/714 complete\n",
      "DEBUG:generate_samples:Batch 15/714 complete\n",
      "DEBUG:generate_samples:Batch 16/714 complete\n",
      "DEBUG:generate_samples:Batch 17/714 complete\n",
      "DEBUG:generate_samples:Batch 18/714 complete\n",
      "DEBUG:generate_samples:Batch 19/714 complete\n",
      "DEBUG:generate_samples:Batch 20/714 complete\n",
      "DEBUG:generate_samples:Batch 21/714 complete\n",
      "DEBUG:generate_samples:Batch 22/714 complete\n",
      "DEBUG:generate_samples:Batch 23/714 complete\n",
      "DEBUG:generate_samples:Batch 24/714 complete\n",
      "DEBUG:generate_samples:Batch 25/714 complete\n",
      "DEBUG:generate_samples:Batch 26/714 complete\n",
      "DEBUG:generate_samples:Batch 27/714 complete\n",
      "DEBUG:generate_samples:Batch 28/714 complete\n",
      "DEBUG:generate_samples:Batch 29/714 complete\n",
      "DEBUG:generate_samples:Batch 30/714 complete\n",
      "DEBUG:generate_samples:Batch 31/714 complete\n",
      "DEBUG:generate_samples:Batch 32/714 complete\n",
      "DEBUG:generate_samples:Batch 33/714 complete\n",
      "DEBUG:generate_samples:Batch 34/714 complete\n",
      "DEBUG:generate_samples:Batch 35/714 complete\n",
      "DEBUG:generate_samples:Batch 36/714 complete\n",
      "DEBUG:generate_samples:Batch 37/714 complete\n",
      "DEBUG:generate_samples:Batch 38/714 complete\n",
      "DEBUG:generate_samples:Batch 39/714 complete\n",
      "DEBUG:generate_samples:Batch 40/714 complete\n",
      "DEBUG:generate_samples:Batch 41/714 complete\n",
      "DEBUG:generate_samples:Batch 42/714 complete\n",
      "DEBUG:generate_samples:Batch 43/714 complete\n",
      "DEBUG:generate_samples:Batch 44/714 complete\n",
      "DEBUG:generate_samples:Batch 45/714 complete\n",
      "DEBUG:generate_samples:Batch 46/714 complete\n",
      "DEBUG:generate_samples:Batch 47/714 complete\n",
      "DEBUG:generate_samples:Batch 48/714 complete\n",
      "DEBUG:generate_samples:Batch 49/714 complete\n",
      "DEBUG:generate_samples:Batch 50/714 complete\n",
      "DEBUG:generate_samples:Batch 51/714 complete\n",
      "DEBUG:generate_samples:Batch 52/714 complete\n",
      "DEBUG:generate_samples:Batch 53/714 complete\n",
      "DEBUG:generate_samples:Batch 54/714 complete\n",
      "DEBUG:generate_samples:Batch 55/714 complete\n",
      "DEBUG:generate_samples:Batch 56/714 complete\n",
      "DEBUG:generate_samples:Batch 57/714 complete\n",
      "DEBUG:generate_samples:Batch 58/714 complete\n",
      "DEBUG:generate_samples:Batch 59/714 complete\n",
      "DEBUG:generate_samples:Batch 60/714 complete\n",
      "DEBUG:generate_samples:Batch 61/714 complete\n",
      "DEBUG:generate_samples:Batch 62/714 complete\n",
      "DEBUG:generate_samples:Batch 63/714 complete\n",
      "DEBUG:generate_samples:Batch 64/714 complete\n",
      "DEBUG:generate_samples:Batch 65/714 complete\n",
      "DEBUG:generate_samples:Batch 66/714 complete\n",
      "DEBUG:generate_samples:Batch 67/714 complete\n",
      "DEBUG:generate_samples:Batch 68/714 complete\n",
      "DEBUG:generate_samples:Batch 69/714 complete\n",
      "DEBUG:generate_samples:Batch 70/714 complete\n",
      "DEBUG:generate_samples:Batch 71/714 complete\n",
      "DEBUG:generate_samples:Batch 72/714 complete\n",
      "DEBUG:generate_samples:Batch 73/714 complete\n",
      "DEBUG:generate_samples:Batch 74/714 complete\n",
      "DEBUG:generate_samples:Batch 75/714 complete\n",
      "DEBUG:generate_samples:Batch 76/714 complete\n",
      "DEBUG:generate_samples:Batch 77/714 complete\n",
      "DEBUG:generate_samples:Batch 78/714 complete\n",
      "DEBUG:generate_samples:Batch 79/714 complete\n",
      "DEBUG:generate_samples:Batch 80/714 complete\n",
      "DEBUG:generate_samples:Batch 81/714 complete\n",
      "DEBUG:generate_samples:Batch 82/714 complete\n",
      "DEBUG:generate_samples:Batch 83/714 complete\n",
      "DEBUG:generate_samples:Batch 84/714 complete\n",
      "DEBUG:generate_samples:Batch 85/714 complete\n",
      "DEBUG:generate_samples:Batch 86/714 complete\n",
      "DEBUG:generate_samples:Batch 87/714 complete\n",
      "DEBUG:generate_samples:Batch 88/714 complete\n",
      "DEBUG:generate_samples:Batch 89/714 complete\n",
      "DEBUG:generate_samples:Batch 90/714 complete\n",
      "DEBUG:generate_samples:Batch 91/714 complete\n",
      "DEBUG:generate_samples:Batch 92/714 complete\n",
      "DEBUG:generate_samples:Batch 93/714 complete\n",
      "DEBUG:generate_samples:Batch 94/714 complete\n",
      "DEBUG:generate_samples:Batch 95/714 complete\n",
      "DEBUG:generate_samples:Batch 96/714 complete\n",
      "DEBUG:generate_samples:Batch 97/714 complete\n",
      "DEBUG:generate_samples:Batch 98/714 complete\n",
      "DEBUG:generate_samples:Batch 99/714 complete\n",
      "DEBUG:generate_samples:Batch 100/714 complete\n",
      "DEBUG:generate_samples:Batch 101/714 complete\n",
      "DEBUG:generate_samples:Batch 102/714 complete\n",
      "DEBUG:generate_samples:Batch 103/714 complete\n",
      "DEBUG:generate_samples:Batch 104/714 complete\n",
      "DEBUG:generate_samples:Batch 105/714 complete\n",
      "DEBUG:generate_samples:Batch 106/714 complete\n",
      "DEBUG:generate_samples:Batch 107/714 complete\n",
      "DEBUG:generate_samples:Batch 108/714 complete\n",
      "DEBUG:generate_samples:Batch 109/714 complete\n",
      "DEBUG:generate_samples:Batch 110/714 complete\n",
      "DEBUG:generate_samples:Batch 111/714 complete\n",
      "DEBUG:generate_samples:Batch 112/714 complete\n",
      "DEBUG:generate_samples:Batch 113/714 complete\n",
      "DEBUG:generate_samples:Batch 114/714 complete\n",
      "DEBUG:generate_samples:Batch 115/714 complete\n",
      "DEBUG:generate_samples:Batch 116/714 complete\n",
      "DEBUG:generate_samples:Batch 117/714 complete\n",
      "DEBUG:generate_samples:Batch 118/714 complete\n",
      "DEBUG:generate_samples:Batch 119/714 complete\n",
      "DEBUG:generate_samples:Batch 120/714 complete\n",
      "DEBUG:generate_samples:Batch 121/714 complete\n",
      "DEBUG:generate_samples:Batch 122/714 complete\n",
      "DEBUG:generate_samples:Batch 123/714 complete\n",
      "DEBUG:generate_samples:Batch 124/714 complete\n",
      "DEBUG:generate_samples:Batch 125/714 complete\n",
      "DEBUG:generate_samples:Batch 126/714 complete\n",
      "DEBUG:generate_samples:Batch 127/714 complete\n",
      "DEBUG:generate_samples:Batch 128/714 complete\n",
      "DEBUG:generate_samples:Batch 129/714 complete\n",
      "DEBUG:generate_samples:Batch 130/714 complete\n",
      "DEBUG:generate_samples:Batch 131/714 complete\n",
      "DEBUG:generate_samples:Batch 132/714 complete\n",
      "DEBUG:generate_samples:Batch 133/714 complete\n",
      "DEBUG:generate_samples:Batch 134/714 complete\n",
      "DEBUG:generate_samples:Batch 135/714 complete\n",
      "DEBUG:generate_samples:Batch 136/714 complete\n",
      "DEBUG:generate_samples:Batch 137/714 complete\n",
      "DEBUG:generate_samples:Batch 138/714 complete\n",
      "DEBUG:generate_samples:Batch 139/714 complete\n",
      "DEBUG:generate_samples:Batch 140/714 complete\n",
      "DEBUG:generate_samples:Batch 141/714 complete\n",
      "DEBUG:generate_samples:Batch 142/714 complete\n",
      "DEBUG:generate_samples:Batch 143/714 complete\n",
      "DEBUG:generate_samples:Batch 144/714 complete\n",
      "DEBUG:generate_samples:Batch 145/714 complete\n",
      "DEBUG:generate_samples:Batch 146/714 complete\n",
      "DEBUG:generate_samples:Batch 147/714 complete\n",
      "DEBUG:generate_samples:Batch 148/714 complete\n",
      "DEBUG:generate_samples:Batch 149/714 complete\n",
      "DEBUG:generate_samples:Batch 150/714 complete\n",
      "DEBUG:generate_samples:Batch 151/714 complete\n",
      "DEBUG:generate_samples:Batch 152/714 complete\n",
      "DEBUG:generate_samples:Batch 153/714 complete\n",
      "DEBUG:generate_samples:Batch 154/714 complete\n",
      "DEBUG:generate_samples:Batch 155/714 complete\n",
      "DEBUG:generate_samples:Batch 156/714 complete\n",
      "DEBUG:generate_samples:Batch 157/714 complete\n",
      "DEBUG:generate_samples:Batch 158/714 complete\n",
      "DEBUG:generate_samples:Batch 159/714 complete\n",
      "DEBUG:generate_samples:Batch 160/714 complete\n",
      "DEBUG:generate_samples:Batch 161/714 complete\n",
      "DEBUG:generate_samples:Batch 162/714 complete\n",
      "DEBUG:generate_samples:Batch 163/714 complete\n",
      "DEBUG:generate_samples:Batch 164/714 complete\n",
      "DEBUG:generate_samples:Batch 165/714 complete\n",
      "DEBUG:generate_samples:Batch 166/714 complete\n",
      "DEBUG:generate_samples:Batch 167/714 complete\n",
      "DEBUG:generate_samples:Batch 168/714 complete\n",
      "DEBUG:generate_samples:Batch 169/714 complete\n",
      "DEBUG:generate_samples:Batch 170/714 complete\n",
      "DEBUG:generate_samples:Batch 171/714 complete\n",
      "DEBUG:generate_samples:Batch 172/714 complete\n",
      "DEBUG:generate_samples:Batch 173/714 complete\n",
      "DEBUG:generate_samples:Batch 174/714 complete\n",
      "DEBUG:generate_samples:Batch 175/714 complete\n",
      "DEBUG:generate_samples:Batch 176/714 complete\n",
      "DEBUG:generate_samples:Batch 177/714 complete\n",
      "DEBUG:generate_samples:Batch 178/714 complete\n",
      "DEBUG:generate_samples:Batch 179/714 complete\n",
      "DEBUG:generate_samples:Batch 180/714 complete\n",
      "DEBUG:generate_samples:Batch 181/714 complete\n",
      "DEBUG:generate_samples:Batch 182/714 complete\n",
      "DEBUG:generate_samples:Batch 183/714 complete\n",
      "DEBUG:generate_samples:Batch 184/714 complete\n",
      "DEBUG:generate_samples:Batch 185/714 complete\n",
      "DEBUG:generate_samples:Batch 186/714 complete\n",
      "DEBUG:generate_samples:Batch 187/714 complete\n",
      "DEBUG:generate_samples:Batch 188/714 complete\n",
      "DEBUG:generate_samples:Batch 189/714 complete\n",
      "DEBUG:generate_samples:Batch 190/714 complete\n",
      "DEBUG:generate_samples:Batch 191/714 complete\n",
      "DEBUG:generate_samples:Batch 192/714 complete\n",
      "DEBUG:generate_samples:Batch 193/714 complete\n",
      "DEBUG:generate_samples:Batch 194/714 complete\n",
      "DEBUG:generate_samples:Batch 195/714 complete\n",
      "DEBUG:generate_samples:Batch 196/714 complete\n",
      "DEBUG:generate_samples:Batch 197/714 complete\n",
      "DEBUG:generate_samples:Batch 198/714 complete\n",
      "DEBUG:generate_samples:Batch 199/714 complete\n",
      "DEBUG:generate_samples:Batch 200/714 complete\n",
      "DEBUG:generate_samples:Batch 201/714 complete\n",
      "DEBUG:generate_samples:Batch 202/714 complete\n",
      "DEBUG:generate_samples:Batch 203/714 complete\n",
      "DEBUG:generate_samples:Batch 204/714 complete\n",
      "DEBUG:generate_samples:Batch 205/714 complete\n",
      "DEBUG:generate_samples:Batch 206/714 complete\n",
      "DEBUG:generate_samples:Batch 207/714 complete\n",
      "DEBUG:generate_samples:Batch 208/714 complete\n",
      "DEBUG:generate_samples:Batch 209/714 complete\n",
      "DEBUG:generate_samples:Batch 210/714 complete\n",
      "DEBUG:generate_samples:Batch 211/714 complete\n",
      "DEBUG:generate_samples:Batch 212/714 complete\n",
      "DEBUG:generate_samples:Batch 213/714 complete\n",
      "DEBUG:generate_samples:Batch 214/714 complete\n",
      "DEBUG:generate_samples:Batch 215/714 complete\n",
      "DEBUG:generate_samples:Batch 216/714 complete\n",
      "DEBUG:generate_samples:Batch 217/714 complete\n",
      "DEBUG:generate_samples:Batch 218/714 complete\n",
      "DEBUG:generate_samples:Batch 219/714 complete\n",
      "DEBUG:generate_samples:Batch 220/714 complete\n",
      "DEBUG:generate_samples:Batch 221/714 complete\n",
      "DEBUG:generate_samples:Batch 222/714 complete\n",
      "DEBUG:generate_samples:Batch 223/714 complete\n",
      "DEBUG:generate_samples:Batch 224/714 complete\n",
      "DEBUG:generate_samples:Batch 225/714 complete\n",
      "DEBUG:generate_samples:Batch 226/714 complete\n",
      "DEBUG:generate_samples:Batch 227/714 complete\n",
      "DEBUG:generate_samples:Batch 228/714 complete\n",
      "DEBUG:generate_samples:Batch 229/714 complete\n",
      "DEBUG:generate_samples:Batch 230/714 complete\n",
      "DEBUG:generate_samples:Batch 231/714 complete\n",
      "DEBUG:generate_samples:Batch 232/714 complete\n",
      "DEBUG:generate_samples:Batch 233/714 complete\n",
      "DEBUG:generate_samples:Batch 234/714 complete\n",
      "DEBUG:generate_samples:Batch 235/714 complete\n",
      "DEBUG:generate_samples:Batch 236/714 complete\n",
      "DEBUG:generate_samples:Batch 237/714 complete\n",
      "DEBUG:generate_samples:Batch 238/714 complete\n",
      "DEBUG:generate_samples:Batch 239/714 complete\n",
      "DEBUG:generate_samples:Batch 240/714 complete\n",
      "DEBUG:generate_samples:Batch 241/714 complete\n",
      "DEBUG:generate_samples:Batch 242/714 complete\n",
      "DEBUG:generate_samples:Batch 243/714 complete\n",
      "DEBUG:generate_samples:Batch 244/714 complete\n",
      "DEBUG:generate_samples:Batch 245/714 complete\n",
      "DEBUG:generate_samples:Batch 246/714 complete\n",
      "DEBUG:generate_samples:Batch 247/714 complete\n",
      "DEBUG:generate_samples:Batch 248/714 complete\n",
      "DEBUG:generate_samples:Batch 249/714 complete\n",
      "DEBUG:generate_samples:Batch 250/714 complete\n",
      "DEBUG:generate_samples:Batch 251/714 complete\n",
      "DEBUG:generate_samples:Batch 252/714 complete\n",
      "DEBUG:generate_samples:Batch 253/714 complete\n",
      "DEBUG:generate_samples:Batch 254/714 complete\n",
      "DEBUG:generate_samples:Batch 255/714 complete\n",
      "DEBUG:generate_samples:Batch 256/714 complete\n",
      "DEBUG:generate_samples:Batch 257/714 complete\n",
      "DEBUG:generate_samples:Batch 258/714 complete\n",
      "DEBUG:generate_samples:Batch 259/714 complete\n",
      "DEBUG:generate_samples:Batch 260/714 complete\n",
      "DEBUG:generate_samples:Batch 261/714 complete\n",
      "DEBUG:generate_samples:Batch 262/714 complete\n",
      "DEBUG:generate_samples:Batch 263/714 complete\n",
      "DEBUG:generate_samples:Batch 264/714 complete\n",
      "DEBUG:generate_samples:Batch 265/714 complete\n",
      "DEBUG:generate_samples:Batch 266/714 complete\n",
      "DEBUG:generate_samples:Batch 267/714 complete\n",
      "DEBUG:generate_samples:Batch 268/714 complete\n",
      "DEBUG:generate_samples:Batch 269/714 complete\n",
      "DEBUG:generate_samples:Batch 270/714 complete\n",
      "DEBUG:generate_samples:Batch 271/714 complete\n",
      "DEBUG:generate_samples:Batch 272/714 complete\n",
      "DEBUG:generate_samples:Batch 273/714 complete\n",
      "DEBUG:generate_samples:Batch 274/714 complete\n",
      "DEBUG:generate_samples:Batch 275/714 complete\n",
      "DEBUG:generate_samples:Batch 276/714 complete\n",
      "DEBUG:generate_samples:Batch 277/714 complete\n",
      "DEBUG:generate_samples:Batch 278/714 complete\n",
      "DEBUG:generate_samples:Batch 279/714 complete\n",
      "DEBUG:generate_samples:Batch 280/714 complete\n",
      "DEBUG:generate_samples:Batch 281/714 complete\n",
      "DEBUG:generate_samples:Batch 282/714 complete\n",
      "DEBUG:generate_samples:Batch 283/714 complete\n",
      "DEBUG:generate_samples:Batch 284/714 complete\n",
      "DEBUG:generate_samples:Batch 285/714 complete\n",
      "DEBUG:generate_samples:Batch 286/714 complete\n",
      "DEBUG:generate_samples:Batch 287/714 complete\n",
      "DEBUG:generate_samples:Batch 288/714 complete\n",
      "DEBUG:generate_samples:Batch 289/714 complete\n",
      "DEBUG:generate_samples:Batch 290/714 complete\n",
      "DEBUG:generate_samples:Batch 291/714 complete\n",
      "DEBUG:generate_samples:Batch 292/714 complete\n",
      "DEBUG:generate_samples:Batch 293/714 complete\n",
      "DEBUG:generate_samples:Batch 294/714 complete\n",
      "DEBUG:generate_samples:Batch 295/714 complete\n",
      "DEBUG:generate_samples:Batch 296/714 complete\n",
      "DEBUG:generate_samples:Batch 297/714 complete\n",
      "DEBUG:generate_samples:Batch 298/714 complete\n",
      "DEBUG:generate_samples:Batch 299/714 complete\n",
      "DEBUG:generate_samples:Batch 300/714 complete\n",
      "DEBUG:generate_samples:Batch 301/714 complete\n",
      "DEBUG:generate_samples:Batch 302/714 complete\n",
      "DEBUG:generate_samples:Batch 303/714 complete\n",
      "DEBUG:generate_samples:Batch 304/714 complete\n",
      "DEBUG:generate_samples:Batch 305/714 complete\n",
      "DEBUG:generate_samples:Batch 306/714 complete\n",
      "DEBUG:generate_samples:Batch 307/714 complete\n",
      "DEBUG:generate_samples:Batch 308/714 complete\n",
      "DEBUG:generate_samples:Batch 309/714 complete\n",
      "DEBUG:generate_samples:Batch 310/714 complete\n",
      "DEBUG:generate_samples:Batch 311/714 complete\n",
      "DEBUG:generate_samples:Batch 312/714 complete\n",
      "DEBUG:generate_samples:Batch 313/714 complete\n",
      "DEBUG:generate_samples:Batch 314/714 complete\n",
      "DEBUG:generate_samples:Batch 315/714 complete\n",
      "DEBUG:generate_samples:Batch 316/714 complete\n",
      "DEBUG:generate_samples:Batch 317/714 complete\n",
      "DEBUG:generate_samples:Batch 318/714 complete\n",
      "DEBUG:generate_samples:Batch 319/714 complete\n",
      "DEBUG:generate_samples:Batch 320/714 complete\n",
      "DEBUG:generate_samples:Batch 321/714 complete\n",
      "DEBUG:generate_samples:Batch 322/714 complete\n",
      "DEBUG:generate_samples:Batch 323/714 complete\n",
      "DEBUG:generate_samples:Batch 324/714 complete\n",
      "DEBUG:generate_samples:Batch 325/714 complete\n",
      "DEBUG:generate_samples:Batch 326/714 complete\n",
      "DEBUG:generate_samples:Batch 327/714 complete\n",
      "DEBUG:generate_samples:Batch 328/714 complete\n",
      "DEBUG:generate_samples:Batch 329/714 complete\n",
      "DEBUG:generate_samples:Batch 330/714 complete\n",
      "DEBUG:generate_samples:Batch 331/714 complete\n",
      "DEBUG:generate_samples:Batch 332/714 complete\n",
      "DEBUG:generate_samples:Batch 333/714 complete\n",
      "DEBUG:generate_samples:Batch 334/714 complete\n",
      "DEBUG:generate_samples:Batch 335/714 complete\n",
      "DEBUG:generate_samples:Batch 336/714 complete\n",
      "DEBUG:generate_samples:Batch 337/714 complete\n",
      "DEBUG:generate_samples:Batch 338/714 complete\n",
      "DEBUG:generate_samples:Batch 339/714 complete\n",
      "DEBUG:generate_samples:Batch 340/714 complete\n",
      "DEBUG:generate_samples:Batch 341/714 complete\n",
      "DEBUG:generate_samples:Batch 342/714 complete\n",
      "DEBUG:generate_samples:Batch 343/714 complete\n",
      "DEBUG:generate_samples:Batch 344/714 complete\n",
      "DEBUG:generate_samples:Batch 345/714 complete\n",
      "DEBUG:generate_samples:Batch 346/714 complete\n",
      "DEBUG:generate_samples:Batch 347/714 complete\n",
      "DEBUG:generate_samples:Batch 348/714 complete\n",
      "DEBUG:generate_samples:Batch 349/714 complete\n",
      "DEBUG:generate_samples:Batch 350/714 complete\n",
      "DEBUG:generate_samples:Batch 351/714 complete\n",
      "DEBUG:generate_samples:Batch 352/714 complete\n",
      "DEBUG:generate_samples:Batch 353/714 complete\n",
      "DEBUG:generate_samples:Batch 354/714 complete\n",
      "DEBUG:generate_samples:Batch 355/714 complete\n",
      "DEBUG:generate_samples:Batch 356/714 complete\n",
      "DEBUG:generate_samples:Batch 357/714 complete\n",
      "DEBUG:generate_samples:Batch 358/714 complete\n",
      "DEBUG:generate_samples:Batch 359/714 complete\n",
      "DEBUG:generate_samples:Batch 360/714 complete\n",
      "DEBUG:generate_samples:Batch 361/714 complete\n",
      "DEBUG:generate_samples:Batch 362/714 complete\n",
      "DEBUG:generate_samples:Batch 363/714 complete\n",
      "DEBUG:generate_samples:Batch 364/714 complete\n",
      "DEBUG:generate_samples:Batch 365/714 complete\n",
      "DEBUG:generate_samples:Batch 366/714 complete\n",
      "DEBUG:generate_samples:Batch 367/714 complete\n",
      "DEBUG:generate_samples:Batch 368/714 complete\n",
      "DEBUG:generate_samples:Batch 369/714 complete\n",
      "DEBUG:generate_samples:Batch 370/714 complete\n",
      "DEBUG:generate_samples:Batch 371/714 complete\n",
      "DEBUG:generate_samples:Batch 372/714 complete\n",
      "DEBUG:generate_samples:Batch 373/714 complete\n",
      "DEBUG:generate_samples:Batch 374/714 complete\n",
      "DEBUG:generate_samples:Batch 375/714 complete\n",
      "DEBUG:generate_samples:Batch 376/714 complete\n",
      "DEBUG:generate_samples:Batch 377/714 complete\n",
      "DEBUG:generate_samples:Batch 378/714 complete\n",
      "DEBUG:generate_samples:Batch 379/714 complete\n",
      "DEBUG:generate_samples:Batch 380/714 complete\n",
      "DEBUG:generate_samples:Batch 381/714 complete\n",
      "DEBUG:generate_samples:Batch 382/714 complete\n",
      "DEBUG:generate_samples:Batch 383/714 complete\n",
      "DEBUG:generate_samples:Batch 384/714 complete\n",
      "DEBUG:generate_samples:Batch 385/714 complete\n",
      "DEBUG:generate_samples:Batch 386/714 complete\n",
      "DEBUG:generate_samples:Batch 387/714 complete\n",
      "DEBUG:generate_samples:Batch 388/714 complete\n",
      "DEBUG:generate_samples:Batch 389/714 complete\n",
      "DEBUG:generate_samples:Batch 390/714 complete\n",
      "DEBUG:generate_samples:Batch 391/714 complete\n",
      "DEBUG:generate_samples:Batch 392/714 complete\n",
      "DEBUG:generate_samples:Batch 393/714 complete\n",
      "DEBUG:generate_samples:Batch 394/714 complete\n",
      "DEBUG:generate_samples:Batch 395/714 complete\n",
      "DEBUG:generate_samples:Batch 396/714 complete\n",
      "DEBUG:generate_samples:Batch 397/714 complete\n",
      "DEBUG:generate_samples:Batch 398/714 complete\n",
      "DEBUG:generate_samples:Batch 399/714 complete\n",
      "DEBUG:generate_samples:Batch 400/714 complete\n",
      "DEBUG:generate_samples:Batch 401/714 complete\n",
      "DEBUG:generate_samples:Batch 402/714 complete\n",
      "DEBUG:generate_samples:Batch 403/714 complete\n",
      "DEBUG:generate_samples:Batch 404/714 complete\n",
      "DEBUG:generate_samples:Batch 405/714 complete\n",
      "DEBUG:generate_samples:Batch 406/714 complete\n",
      "DEBUG:generate_samples:Batch 407/714 complete\n",
      "DEBUG:generate_samples:Batch 408/714 complete\n",
      "DEBUG:generate_samples:Batch 409/714 complete\n",
      "DEBUG:generate_samples:Batch 410/714 complete\n",
      "DEBUG:generate_samples:Batch 411/714 complete\n",
      "DEBUG:generate_samples:Batch 412/714 complete\n",
      "DEBUG:generate_samples:Batch 413/714 complete\n",
      "DEBUG:generate_samples:Batch 414/714 complete\n",
      "DEBUG:generate_samples:Batch 415/714 complete\n",
      "DEBUG:generate_samples:Batch 416/714 complete\n",
      "DEBUG:generate_samples:Batch 417/714 complete\n",
      "DEBUG:generate_samples:Batch 418/714 complete\n",
      "DEBUG:generate_samples:Batch 419/714 complete\n",
      "DEBUG:generate_samples:Batch 420/714 complete\n",
      "DEBUG:generate_samples:Batch 421/714 complete\n",
      "DEBUG:generate_samples:Batch 422/714 complete\n",
      "DEBUG:generate_samples:Batch 423/714 complete\n",
      "DEBUG:generate_samples:Batch 424/714 complete\n",
      "DEBUG:generate_samples:Batch 425/714 complete\n",
      "DEBUG:generate_samples:Batch 426/714 complete\n",
      "DEBUG:generate_samples:Batch 427/714 complete\n",
      "DEBUG:generate_samples:Batch 428/714 complete\n",
      "DEBUG:generate_samples:Batch 429/714 complete\n",
      "DEBUG:generate_samples:Batch 430/714 complete\n",
      "DEBUG:generate_samples:Batch 431/714 complete\n",
      "DEBUG:generate_samples:Batch 432/714 complete\n",
      "DEBUG:generate_samples:Batch 433/714 complete\n",
      "DEBUG:generate_samples:Batch 434/714 complete\n",
      "DEBUG:generate_samples:Batch 435/714 complete\n",
      "DEBUG:generate_samples:Batch 436/714 complete\n",
      "DEBUG:generate_samples:Batch 437/714 complete\n",
      "DEBUG:generate_samples:Batch 438/714 complete\n",
      "DEBUG:generate_samples:Batch 439/714 complete\n",
      "DEBUG:generate_samples:Batch 440/714 complete\n",
      "DEBUG:generate_samples:Batch 441/714 complete\n",
      "DEBUG:generate_samples:Batch 442/714 complete\n",
      "DEBUG:generate_samples:Batch 443/714 complete\n",
      "DEBUG:generate_samples:Batch 444/714 complete\n",
      "DEBUG:generate_samples:Batch 445/714 complete\n",
      "DEBUG:generate_samples:Batch 446/714 complete\n",
      "DEBUG:generate_samples:Batch 447/714 complete\n",
      "DEBUG:generate_samples:Batch 448/714 complete\n",
      "DEBUG:generate_samples:Batch 449/714 complete\n",
      "DEBUG:generate_samples:Batch 450/714 complete\n",
      "DEBUG:generate_samples:Batch 451/714 complete\n",
      "DEBUG:generate_samples:Batch 452/714 complete\n",
      "DEBUG:generate_samples:Batch 453/714 complete\n",
      "DEBUG:generate_samples:Batch 454/714 complete\n",
      "DEBUG:generate_samples:Batch 455/714 complete\n",
      "DEBUG:generate_samples:Batch 456/714 complete\n",
      "DEBUG:generate_samples:Batch 457/714 complete\n",
      "DEBUG:generate_samples:Batch 458/714 complete\n",
      "DEBUG:generate_samples:Batch 459/714 complete\n",
      "DEBUG:generate_samples:Batch 460/714 complete\n",
      "DEBUG:generate_samples:Batch 461/714 complete\n",
      "DEBUG:generate_samples:Batch 462/714 complete\n",
      "DEBUG:generate_samples:Batch 463/714 complete\n",
      "DEBUG:generate_samples:Batch 464/714 complete\n",
      "DEBUG:generate_samples:Batch 465/714 complete\n",
      "DEBUG:generate_samples:Batch 466/714 complete\n",
      "DEBUG:generate_samples:Batch 467/714 complete\n",
      "DEBUG:generate_samples:Batch 468/714 complete\n",
      "DEBUG:generate_samples:Batch 469/714 complete\n",
      "DEBUG:generate_samples:Batch 470/714 complete\n",
      "DEBUG:generate_samples:Batch 471/714 complete\n",
      "DEBUG:generate_samples:Batch 472/714 complete\n",
      "DEBUG:generate_samples:Batch 473/714 complete\n",
      "DEBUG:generate_samples:Batch 474/714 complete\n",
      "DEBUG:generate_samples:Batch 475/714 complete\n",
      "DEBUG:generate_samples:Batch 476/714 complete\n",
      "DEBUG:generate_samples:Batch 477/714 complete\n",
      "DEBUG:generate_samples:Batch 478/714 complete\n",
      "DEBUG:generate_samples:Batch 479/714 complete\n",
      "DEBUG:generate_samples:Batch 480/714 complete\n",
      "DEBUG:generate_samples:Batch 481/714 complete\n",
      "DEBUG:generate_samples:Batch 482/714 complete\n",
      "DEBUG:generate_samples:Batch 483/714 complete\n",
      "DEBUG:generate_samples:Batch 484/714 complete\n",
      "DEBUG:generate_samples:Batch 485/714 complete\n",
      "DEBUG:generate_samples:Batch 486/714 complete\n",
      "DEBUG:generate_samples:Batch 487/714 complete\n",
      "DEBUG:generate_samples:Batch 488/714 complete\n",
      "DEBUG:generate_samples:Batch 489/714 complete\n",
      "DEBUG:generate_samples:Batch 490/714 complete\n",
      "DEBUG:generate_samples:Batch 491/714 complete\n",
      "DEBUG:generate_samples:Batch 492/714 complete\n",
      "DEBUG:generate_samples:Batch 493/714 complete\n",
      "DEBUG:generate_samples:Batch 494/714 complete\n",
      "DEBUG:generate_samples:Batch 495/714 complete\n",
      "DEBUG:generate_samples:Batch 496/714 complete\n",
      "DEBUG:generate_samples:Batch 497/714 complete\n",
      "DEBUG:generate_samples:Batch 498/714 complete\n",
      "DEBUG:generate_samples:Batch 499/714 complete\n",
      "DEBUG:generate_samples:Batch 500/714 complete\n",
      "DEBUG:generate_samples:Batch 501/714 complete\n",
      "DEBUG:generate_samples:Batch 502/714 complete\n",
      "DEBUG:generate_samples:Batch 503/714 complete\n",
      "DEBUG:generate_samples:Batch 504/714 complete\n",
      "DEBUG:generate_samples:Batch 505/714 complete\n",
      "DEBUG:generate_samples:Batch 506/714 complete\n",
      "DEBUG:generate_samples:Batch 507/714 complete\n",
      "DEBUG:generate_samples:Batch 508/714 complete\n",
      "DEBUG:generate_samples:Batch 509/714 complete\n",
      "DEBUG:generate_samples:Batch 510/714 complete\n",
      "DEBUG:generate_samples:Batch 511/714 complete\n",
      "DEBUG:generate_samples:Batch 512/714 complete\n",
      "DEBUG:generate_samples:Batch 513/714 complete\n",
      "DEBUG:generate_samples:Batch 514/714 complete\n",
      "DEBUG:generate_samples:Batch 515/714 complete\n",
      "DEBUG:generate_samples:Batch 516/714 complete\n",
      "DEBUG:generate_samples:Batch 517/714 complete\n",
      "DEBUG:generate_samples:Batch 518/714 complete\n",
      "DEBUG:generate_samples:Batch 519/714 complete\n",
      "DEBUG:generate_samples:Batch 520/714 complete\n",
      "DEBUG:generate_samples:Batch 521/714 complete\n",
      "DEBUG:generate_samples:Batch 522/714 complete\n",
      "DEBUG:generate_samples:Batch 523/714 complete\n",
      "DEBUG:generate_samples:Batch 524/714 complete\n",
      "DEBUG:generate_samples:Batch 525/714 complete\n",
      "DEBUG:generate_samples:Batch 526/714 complete\n",
      "DEBUG:generate_samples:Batch 527/714 complete\n",
      "DEBUG:generate_samples:Batch 528/714 complete\n",
      "DEBUG:generate_samples:Batch 529/714 complete\n",
      "DEBUG:generate_samples:Batch 530/714 complete\n",
      "DEBUG:generate_samples:Batch 531/714 complete\n",
      "DEBUG:generate_samples:Batch 532/714 complete\n",
      "DEBUG:generate_samples:Batch 533/714 complete\n",
      "DEBUG:generate_samples:Batch 534/714 complete\n",
      "DEBUG:generate_samples:Batch 535/714 complete\n",
      "DEBUG:generate_samples:Batch 536/714 complete\n",
      "DEBUG:generate_samples:Batch 537/714 complete\n",
      "DEBUG:generate_samples:Batch 538/714 complete\n",
      "DEBUG:generate_samples:Batch 539/714 complete\n",
      "DEBUG:generate_samples:Batch 540/714 complete\n",
      "DEBUG:generate_samples:Batch 541/714 complete\n",
      "DEBUG:generate_samples:Batch 542/714 complete\n",
      "DEBUG:generate_samples:Batch 543/714 complete\n",
      "DEBUG:generate_samples:Batch 544/714 complete\n",
      "DEBUG:generate_samples:Batch 545/714 complete\n",
      "DEBUG:generate_samples:Batch 546/714 complete\n",
      "DEBUG:generate_samples:Batch 547/714 complete\n",
      "DEBUG:generate_samples:Batch 548/714 complete\n",
      "DEBUG:generate_samples:Batch 549/714 complete\n",
      "DEBUG:generate_samples:Batch 550/714 complete\n",
      "DEBUG:generate_samples:Batch 551/714 complete\n",
      "DEBUG:generate_samples:Batch 552/714 complete\n",
      "DEBUG:generate_samples:Batch 553/714 complete\n",
      "DEBUG:generate_samples:Batch 554/714 complete\n",
      "DEBUG:generate_samples:Batch 555/714 complete\n",
      "DEBUG:generate_samples:Batch 556/714 complete\n",
      "DEBUG:generate_samples:Batch 557/714 complete\n",
      "DEBUG:generate_samples:Batch 558/714 complete\n",
      "DEBUG:generate_samples:Batch 559/714 complete\n",
      "DEBUG:generate_samples:Batch 560/714 complete\n",
      "DEBUG:generate_samples:Batch 561/714 complete\n",
      "DEBUG:generate_samples:Batch 562/714 complete\n",
      "DEBUG:generate_samples:Batch 563/714 complete\n",
      "DEBUG:generate_samples:Batch 564/714 complete\n",
      "DEBUG:generate_samples:Batch 565/714 complete\n",
      "DEBUG:generate_samples:Batch 566/714 complete\n",
      "DEBUG:generate_samples:Batch 567/714 complete\n",
      "DEBUG:generate_samples:Batch 568/714 complete\n",
      "DEBUG:generate_samples:Batch 569/714 complete\n",
      "DEBUG:generate_samples:Batch 570/714 complete\n",
      "DEBUG:generate_samples:Batch 571/714 complete\n",
      "DEBUG:generate_samples:Batch 572/714 complete\n",
      "DEBUG:generate_samples:Batch 573/714 complete\n",
      "DEBUG:generate_samples:Batch 574/714 complete\n",
      "DEBUG:generate_samples:Batch 575/714 complete\n",
      "DEBUG:generate_samples:Batch 576/714 complete\n",
      "DEBUG:generate_samples:Batch 577/714 complete\n",
      "DEBUG:generate_samples:Batch 578/714 complete\n",
      "DEBUG:generate_samples:Batch 579/714 complete\n",
      "DEBUG:generate_samples:Batch 580/714 complete\n",
      "DEBUG:generate_samples:Batch 581/714 complete\n",
      "DEBUG:generate_samples:Batch 582/714 complete\n",
      "DEBUG:generate_samples:Batch 583/714 complete\n",
      "DEBUG:generate_samples:Batch 584/714 complete\n",
      "DEBUG:generate_samples:Batch 585/714 complete\n",
      "DEBUG:generate_samples:Batch 586/714 complete\n",
      "DEBUG:generate_samples:Batch 587/714 complete\n",
      "DEBUG:generate_samples:Batch 588/714 complete\n",
      "DEBUG:generate_samples:Batch 589/714 complete\n",
      "DEBUG:generate_samples:Batch 590/714 complete\n",
      "DEBUG:generate_samples:Batch 591/714 complete\n",
      "DEBUG:generate_samples:Batch 592/714 complete\n",
      "DEBUG:generate_samples:Batch 593/714 complete\n",
      "DEBUG:generate_samples:Batch 594/714 complete\n",
      "DEBUG:generate_samples:Batch 595/714 complete\n",
      "DEBUG:generate_samples:Batch 596/714 complete\n",
      "DEBUG:generate_samples:Batch 597/714 complete\n",
      "DEBUG:generate_samples:Batch 598/714 complete\n",
      "DEBUG:generate_samples:Batch 599/714 complete\n",
      "DEBUG:generate_samples:Batch 600/714 complete\n",
      "DEBUG:generate_samples:Batch 601/714 complete\n",
      "DEBUG:generate_samples:Batch 602/714 complete\n",
      "DEBUG:generate_samples:Batch 603/714 complete\n",
      "DEBUG:generate_samples:Batch 604/714 complete\n",
      "DEBUG:generate_samples:Batch 605/714 complete\n",
      "DEBUG:generate_samples:Batch 606/714 complete\n",
      "DEBUG:generate_samples:Batch 607/714 complete\n",
      "DEBUG:generate_samples:Batch 608/714 complete\n",
      "DEBUG:generate_samples:Batch 609/714 complete\n",
      "DEBUG:generate_samples:Batch 610/714 complete\n",
      "DEBUG:generate_samples:Batch 611/714 complete\n",
      "DEBUG:generate_samples:Batch 612/714 complete\n",
      "DEBUG:generate_samples:Batch 613/714 complete\n",
      "DEBUG:generate_samples:Batch 614/714 complete\n",
      "DEBUG:generate_samples:Batch 615/714 complete\n",
      "DEBUG:generate_samples:Batch 616/714 complete\n",
      "DEBUG:generate_samples:Batch 617/714 complete\n",
      "DEBUG:generate_samples:Batch 618/714 complete\n",
      "DEBUG:generate_samples:Batch 619/714 complete\n",
      "DEBUG:generate_samples:Batch 620/714 complete\n",
      "DEBUG:generate_samples:Batch 621/714 complete\n",
      "DEBUG:generate_samples:Batch 622/714 complete\n",
      "DEBUG:generate_samples:Batch 623/714 complete\n",
      "DEBUG:generate_samples:Batch 624/714 complete\n",
      "DEBUG:generate_samples:Batch 625/714 complete\n",
      "DEBUG:generate_samples:Batch 626/714 complete\n",
      "DEBUG:generate_samples:Batch 627/714 complete\n",
      "DEBUG:generate_samples:Batch 628/714 complete\n",
      "DEBUG:generate_samples:Batch 629/714 complete\n",
      "DEBUG:generate_samples:Batch 630/714 complete\n",
      "DEBUG:generate_samples:Batch 631/714 complete\n",
      "DEBUG:generate_samples:Batch 632/714 complete\n",
      "DEBUG:generate_samples:Batch 633/714 complete\n",
      "DEBUG:generate_samples:Batch 634/714 complete\n",
      "DEBUG:generate_samples:Batch 635/714 complete\n",
      "DEBUG:generate_samples:Batch 636/714 complete\n",
      "DEBUG:generate_samples:Batch 637/714 complete\n",
      "DEBUG:generate_samples:Batch 638/714 complete\n",
      "DEBUG:generate_samples:Batch 639/714 complete\n",
      "DEBUG:generate_samples:Batch 640/714 complete\n",
      "DEBUG:generate_samples:Batch 641/714 complete\n",
      "DEBUG:generate_samples:Batch 642/714 complete\n",
      "DEBUG:generate_samples:Batch 643/714 complete\n",
      "DEBUG:generate_samples:Batch 644/714 complete\n",
      "DEBUG:generate_samples:Batch 645/714 complete\n",
      "DEBUG:generate_samples:Batch 646/714 complete\n",
      "DEBUG:generate_samples:Batch 647/714 complete\n",
      "DEBUG:generate_samples:Batch 648/714 complete\n",
      "DEBUG:generate_samples:Batch 649/714 complete\n",
      "DEBUG:generate_samples:Batch 650/714 complete\n",
      "DEBUG:generate_samples:Batch 651/714 complete\n",
      "DEBUG:generate_samples:Batch 652/714 complete\n",
      "DEBUG:generate_samples:Batch 653/714 complete\n",
      "DEBUG:generate_samples:Batch 654/714 complete\n",
      "DEBUG:generate_samples:Batch 655/714 complete\n",
      "DEBUG:generate_samples:Batch 656/714 complete\n",
      "DEBUG:generate_samples:Batch 657/714 complete\n",
      "DEBUG:generate_samples:Batch 658/714 complete\n",
      "DEBUG:generate_samples:Batch 659/714 complete\n",
      "DEBUG:generate_samples:Batch 660/714 complete\n",
      "DEBUG:generate_samples:Batch 661/714 complete\n",
      "DEBUG:generate_samples:Batch 662/714 complete\n",
      "DEBUG:generate_samples:Batch 663/714 complete\n",
      "DEBUG:generate_samples:Batch 664/714 complete\n",
      "DEBUG:generate_samples:Batch 665/714 complete\n",
      "DEBUG:generate_samples:Batch 666/714 complete\n",
      "DEBUG:generate_samples:Batch 667/714 complete\n",
      "DEBUG:generate_samples:Batch 668/714 complete\n",
      "DEBUG:generate_samples:Batch 669/714 complete\n",
      "DEBUG:generate_samples:Batch 670/714 complete\n",
      "DEBUG:generate_samples:Batch 671/714 complete\n",
      "DEBUG:generate_samples:Batch 672/714 complete\n",
      "DEBUG:generate_samples:Batch 673/714 complete\n",
      "DEBUG:generate_samples:Batch 674/714 complete\n",
      "DEBUG:generate_samples:Batch 675/714 complete\n",
      "DEBUG:generate_samples:Batch 676/714 complete\n",
      "DEBUG:generate_samples:Batch 677/714 complete\n",
      "DEBUG:generate_samples:Batch 678/714 complete\n",
      "DEBUG:generate_samples:Batch 679/714 complete\n",
      "DEBUG:generate_samples:Batch 680/714 complete\n",
      "DEBUG:generate_samples:Batch 681/714 complete\n",
      "DEBUG:generate_samples:Batch 682/714 complete\n",
      "DEBUG:generate_samples:Batch 683/714 complete\n",
      "DEBUG:generate_samples:Batch 684/714 complete\n",
      "DEBUG:generate_samples:Batch 685/714 complete\n",
      "DEBUG:generate_samples:Batch 686/714 complete\n",
      "DEBUG:generate_samples:Batch 687/714 complete\n",
      "DEBUG:generate_samples:Batch 688/714 complete\n",
      "DEBUG:generate_samples:Batch 689/714 complete\n",
      "DEBUG:generate_samples:Batch 690/714 complete\n",
      "DEBUG:generate_samples:Batch 691/714 complete\n",
      "DEBUG:generate_samples:Batch 692/714 complete\n",
      "DEBUG:generate_samples:Batch 693/714 complete\n",
      "DEBUG:generate_samples:Batch 694/714 complete\n",
      "DEBUG:generate_samples:Batch 695/714 complete\n",
      "DEBUG:generate_samples:Batch 696/714 complete\n",
      "DEBUG:generate_samples:Batch 697/714 complete\n",
      "DEBUG:generate_samples:Batch 698/714 complete\n",
      "DEBUG:generate_samples:Batch 699/714 complete\n",
      "DEBUG:generate_samples:Batch 700/714 complete\n",
      "DEBUG:generate_samples:Batch 701/714 complete\n",
      "DEBUG:generate_samples:Batch 702/714 complete\n",
      "DEBUG:generate_samples:Batch 703/714 complete\n",
      "DEBUG:generate_samples:Batch 704/714 complete\n",
      "DEBUG:generate_samples:Batch 705/714 complete\n",
      "DEBUG:generate_samples:Batch 706/714 complete\n",
      "DEBUG:generate_samples:Batch 707/714 complete\n",
      "DEBUG:generate_samples:Batch 708/714 complete\n",
      "DEBUG:generate_samples:Batch 709/714 complete\n",
      "DEBUG:generate_samples:Batch 710/714 complete\n",
      "DEBUG:generate_samples:Batch 711/714 complete\n",
      "DEBUG:generate_samples:Batch 712/714 complete\n",
      "DEBUG:generate_samples:Batch 713/714 complete\n",
      "DEBUG:generate_samples:Batch 714/714 complete\n",
      "DEBUG:generate_samples:Batch 715/714 complete\n",
      "INFO:generate_samples:Done\n",
      "INFO:root:##################################################\n",
      "Generating negative clips for testing\n",
      "##################################################\n",
      "DEBUG:dp.phonemizer:Initializing phonemizer with model step 1120000\n",
      "WARNING:root:The word 'nixberry' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
      "WARNING:root:Phones for 'nixberry': [N][IH][K][S][B][EH][R][IY]\n",
      "DEBUG:generate_samples:Loading ./piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
      "INFO:generate_samples:Successfully loaded the model\n",
      "DEBUG:generate_samples:CUDA available, using GPU\n",
      "DEBUG:generate_samples:Batch 1/142 complete\n",
      "DEBUG:generate_samples:Batch 2/142 complete\n",
      "DEBUG:generate_samples:Batch 3/142 complete\n",
      "DEBUG:generate_samples:Batch 4/142 complete\n",
      "DEBUG:generate_samples:Batch 5/142 complete\n",
      "DEBUG:generate_samples:Batch 6/142 complete\n",
      "DEBUG:generate_samples:Batch 7/142 complete\n",
      "DEBUG:generate_samples:Batch 8/142 complete\n",
      "DEBUG:generate_samples:Batch 9/142 complete\n",
      "DEBUG:generate_samples:Batch 10/142 complete\n",
      "DEBUG:generate_samples:Batch 11/142 complete\n",
      "DEBUG:generate_samples:Batch 12/142 complete\n",
      "DEBUG:generate_samples:Batch 13/142 complete\n",
      "DEBUG:generate_samples:Batch 14/142 complete\n",
      "DEBUG:generate_samples:Batch 15/142 complete\n",
      "DEBUG:generate_samples:Batch 16/142 complete\n",
      "DEBUG:generate_samples:Batch 17/142 complete\n",
      "DEBUG:generate_samples:Batch 18/142 complete\n",
      "DEBUG:generate_samples:Batch 19/142 complete\n",
      "DEBUG:generate_samples:Batch 20/142 complete\n",
      "DEBUG:generate_samples:Batch 21/142 complete\n",
      "DEBUG:generate_samples:Batch 22/142 complete\n",
      "DEBUG:generate_samples:Batch 23/142 complete\n",
      "DEBUG:generate_samples:Batch 24/142 complete\n",
      "DEBUG:generate_samples:Batch 25/142 complete\n",
      "DEBUG:generate_samples:Batch 26/142 complete\n",
      "DEBUG:generate_samples:Batch 27/142 complete\n",
      "DEBUG:generate_samples:Batch 28/142 complete\n",
      "DEBUG:generate_samples:Batch 29/142 complete\n",
      "DEBUG:generate_samples:Batch 30/142 complete\n",
      "DEBUG:generate_samples:Batch 31/142 complete\n",
      "DEBUG:generate_samples:Batch 32/142 complete\n",
      "DEBUG:generate_samples:Batch 33/142 complete\n",
      "DEBUG:generate_samples:Batch 34/142 complete\n",
      "DEBUG:generate_samples:Batch 35/142 complete\n",
      "DEBUG:generate_samples:Batch 36/142 complete\n",
      "DEBUG:generate_samples:Batch 37/142 complete\n",
      "DEBUG:generate_samples:Batch 38/142 complete\n",
      "DEBUG:generate_samples:Batch 39/142 complete\n",
      "DEBUG:generate_samples:Batch 40/142 complete\n",
      "DEBUG:generate_samples:Batch 41/142 complete\n",
      "DEBUG:generate_samples:Batch 42/142 complete\n",
      "DEBUG:generate_samples:Batch 43/142 complete\n",
      "DEBUG:generate_samples:Batch 44/142 complete\n",
      "DEBUG:generate_samples:Batch 45/142 complete\n",
      "DEBUG:generate_samples:Batch 46/142 complete\n",
      "DEBUG:generate_samples:Batch 47/142 complete\n",
      "DEBUG:generate_samples:Batch 48/142 complete\n",
      "DEBUG:generate_samples:Batch 49/142 complete\n",
      "DEBUG:generate_samples:Batch 50/142 complete\n",
      "DEBUG:generate_samples:Batch 51/142 complete\n",
      "DEBUG:generate_samples:Batch 52/142 complete\n",
      "DEBUG:generate_samples:Batch 53/142 complete\n",
      "DEBUG:generate_samples:Batch 54/142 complete\n",
      "DEBUG:generate_samples:Batch 55/142 complete\n",
      "DEBUG:generate_samples:Batch 56/142 complete\n",
      "DEBUG:generate_samples:Batch 57/142 complete\n",
      "DEBUG:generate_samples:Batch 58/142 complete\n",
      "DEBUG:generate_samples:Batch 59/142 complete\n",
      "DEBUG:generate_samples:Batch 60/142 complete\n",
      "DEBUG:generate_samples:Batch 61/142 complete\n",
      "DEBUG:generate_samples:Batch 62/142 complete\n",
      "DEBUG:generate_samples:Batch 63/142 complete\n",
      "DEBUG:generate_samples:Batch 64/142 complete\n",
      "DEBUG:generate_samples:Batch 65/142 complete\n",
      "DEBUG:generate_samples:Batch 66/142 complete\n",
      "DEBUG:generate_samples:Batch 67/142 complete\n",
      "DEBUG:generate_samples:Batch 68/142 complete\n",
      "DEBUG:generate_samples:Batch 69/142 complete\n",
      "DEBUG:generate_samples:Batch 70/142 complete\n",
      "DEBUG:generate_samples:Batch 71/142 complete\n",
      "DEBUG:generate_samples:Batch 72/142 complete\n",
      "DEBUG:generate_samples:Batch 73/142 complete\n",
      "DEBUG:generate_samples:Batch 74/142 complete\n",
      "DEBUG:generate_samples:Batch 75/142 complete\n",
      "DEBUG:generate_samples:Batch 76/142 complete\n",
      "DEBUG:generate_samples:Batch 77/142 complete\n",
      "DEBUG:generate_samples:Batch 78/142 complete\n",
      "DEBUG:generate_samples:Batch 79/142 complete\n",
      "DEBUG:generate_samples:Batch 80/142 complete\n",
      "DEBUG:generate_samples:Batch 81/142 complete\n",
      "DEBUG:generate_samples:Batch 82/142 complete\n",
      "DEBUG:generate_samples:Batch 83/142 complete\n",
      "DEBUG:generate_samples:Batch 84/142 complete\n",
      "DEBUG:generate_samples:Batch 85/142 complete\n",
      "DEBUG:generate_samples:Batch 86/142 complete\n",
      "DEBUG:generate_samples:Batch 87/142 complete\n",
      "DEBUG:generate_samples:Batch 88/142 complete\n",
      "DEBUG:generate_samples:Batch 89/142 complete\n",
      "DEBUG:generate_samples:Batch 90/142 complete\n",
      "DEBUG:generate_samples:Batch 91/142 complete\n",
      "DEBUG:generate_samples:Batch 92/142 complete\n",
      "DEBUG:generate_samples:Batch 93/142 complete\n",
      "DEBUG:generate_samples:Batch 94/142 complete\n",
      "DEBUG:generate_samples:Batch 95/142 complete\n",
      "DEBUG:generate_samples:Batch 96/142 complete\n",
      "DEBUG:generate_samples:Batch 97/142 complete\n",
      "DEBUG:generate_samples:Batch 98/142 complete\n",
      "DEBUG:generate_samples:Batch 99/142 complete\n",
      "DEBUG:generate_samples:Batch 100/142 complete\n",
      "DEBUG:generate_samples:Batch 101/142 complete\n",
      "DEBUG:generate_samples:Batch 102/142 complete\n",
      "DEBUG:generate_samples:Batch 103/142 complete\n",
      "DEBUG:generate_samples:Batch 104/142 complete\n",
      "DEBUG:generate_samples:Batch 105/142 complete\n",
      "DEBUG:generate_samples:Batch 106/142 complete\n",
      "DEBUG:generate_samples:Batch 107/142 complete\n",
      "DEBUG:generate_samples:Batch 108/142 complete\n",
      "DEBUG:generate_samples:Batch 109/142 complete\n",
      "DEBUG:generate_samples:Batch 110/142 complete\n",
      "DEBUG:generate_samples:Batch 111/142 complete\n",
      "DEBUG:generate_samples:Batch 112/142 complete\n",
      "DEBUG:generate_samples:Batch 113/142 complete\n",
      "DEBUG:generate_samples:Batch 114/142 complete\n",
      "DEBUG:generate_samples:Batch 115/142 complete\n",
      "DEBUG:generate_samples:Batch 116/142 complete\n",
      "DEBUG:generate_samples:Batch 117/142 complete\n",
      "DEBUG:generate_samples:Batch 118/142 complete\n",
      "DEBUG:generate_samples:Batch 119/142 complete\n",
      "DEBUG:generate_samples:Batch 120/142 complete\n",
      "DEBUG:generate_samples:Batch 121/142 complete\n",
      "DEBUG:generate_samples:Batch 122/142 complete\n",
      "DEBUG:generate_samples:Batch 123/142 complete\n",
      "DEBUG:generate_samples:Batch 124/142 complete\n",
      "DEBUG:generate_samples:Batch 125/142 complete\n",
      "DEBUG:generate_samples:Batch 126/142 complete\n",
      "DEBUG:generate_samples:Batch 127/142 complete\n",
      "DEBUG:generate_samples:Batch 128/142 complete\n",
      "DEBUG:generate_samples:Batch 129/142 complete\n",
      "DEBUG:generate_samples:Batch 130/142 complete\n",
      "DEBUG:generate_samples:Batch 131/142 complete\n",
      "DEBUG:generate_samples:Batch 132/142 complete\n",
      "DEBUG:generate_samples:Batch 133/142 complete\n",
      "DEBUG:generate_samples:Batch 134/142 complete\n",
      "DEBUG:generate_samples:Batch 135/142 complete\n",
      "DEBUG:generate_samples:Batch 136/142 complete\n",
      "DEBUG:generate_samples:Batch 137/142 complete\n",
      "DEBUG:generate_samples:Batch 138/142 complete\n",
      "DEBUG:generate_samples:Batch 139/142 complete\n",
      "DEBUG:generate_samples:Batch 140/142 complete\n",
      "DEBUG:generate_samples:Batch 141/142 complete\n",
      "DEBUG:generate_samples:Batch 142/142 complete\n",
      "DEBUG:generate_samples:Batch 143/142 complete\n",
      "INFO:generate_samples:Done\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate synthetic clips\n",
    "import sys\n",
    "import os\n",
    "\n",
    "!pip install 'numpy<2' piper-tts\n",
    "\n",
    "# Create resources directory in local clone\n",
    "os.makedirs('./openwakeword/openwakeword/resources', exist_ok=True)\n",
    "\n",
    "# Patch the local data.py to use exist_ok=True\n",
    "import_path = './openwakeword/openwakeword/data.py'\n",
    "with open(import_path, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "content = content.replace(\n",
    "    'os.mkdir(os.path.join(os.path.dirname(os.path.abspath(__file__)), \"resources\"))',\n",
    "    'os.makedirs(os.path.join(os.path.dirname(os.path.abspath(__file__)), \"resources\"), exist_ok=True)'\n",
    ")\n",
    "\n",
    "with open(import_path, 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Use local openwakeword\n",
    "sys.path.insert(0, '/home/jovyan/openwakeword')\n",
    "\n",
    "# Run with proper PYTHONPATH\n",
    "!PYTHONPATH=/home/jovyan/openwakeword:$PYTHONPATH python3 openwakeword/openwakeword/train.py --training_config my_model.yaml --generate_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeedae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T13:56:08.781018Z",
     "start_time": "2023-09-04T13:55:40.203515Z"
    },
    "id": "afeedae4"
   },
   "outputs": [],
   "source": [
    "# Fix sample rate issue before augmentation\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def fix_sample_rate(directory, target_sr=16000):\n",
    "    for wav_file in Path(directory).glob(\"*.wav\"):\n",
    "        sr, data = scipy.io.wavfile.read(wav_file)\n",
    "        if sr != target_sr:\n",
    "            print(f\"Resampling {wav_file.name} from {sr} to {target_sr}\")\n",
    "            # Simple resampling using scipy\n",
    "            from scipy import signal\n",
    "            num_samples = int(len(data) * target_sr / sr)\n",
    "            resampled = signal.resample(data, num_samples)\n",
    "            scipy.io.wavfile.write(wav_file, target_sr, resampled.astype(data.dtype))\n",
    "\n",
    "# Fix all generated clips\n",
    "fix_sample_rate('./my_custom_model/nixberry/positive_train')\n",
    "fix_sample_rate('./my_custom_model/nixberry/positive_test')\n",
    "fix_sample_rate('./my_custom_model/nixberry/negative_train')\n",
    "fix_sample_rate('./my_custom_model/nixberry/negative_test')\n",
    "\n",
    "# Now run augmentation\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/openwakeword')\n",
    "!PYTHONPATH=/home/jovyan/openwakeword:$PYTHONPATH python3 openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ad81ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:11:14.742260Z",
     "start_time": "2023-09-04T15:07:03.755159Z"
    },
    "id": "9ad81ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/pronouncing/__init__.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream\n",
      "torchvision is not available - cannot save figures\n",
      "INFO:root:##################################################\n",
      "Starting training sequence 1...\n",
      "##################################################\n",
      "Training: 100%|███████████████████████████▉| 9999/10000 [03:55<00:00, 42.53it/s]\n",
      "INFO:root:##################################################\n",
      "Starting training sequence 2...\n",
      "##################################################\n",
      "INFO:root:Increasing weight on negative examples to reduce false positives...\n",
      "Training: 100%|███████████████████████████▉| 999/1000.0 [02:38<00:00,  6.30it/s]\n",
      "INFO:root:##################################################\n",
      "Starting training sequence 3...\n",
      "##################################################\n",
      "INFO:root:Increasing weight on negative examples to reduce false positives...\n",
      "Training: 100%|███████████████████████████▉| 999/1000.0 [02:41<00:00,  6.20it/s]\n",
      "INFO:root:Merging checkpoints above the 90th percentile into single model...\n",
      "INFO:root:\n",
      "################\n",
      "Final Model Accuracy: 0.690500020980835\n",
      "Final Model Recall: 0.38100001215934753\n",
      "Final Model False Positives per Hour: 2.4778761863708496\n",
      "################\n",
      "\n",
      "INFO:root:####\n",
      "Saving ONNX mode as '/home/jovyan/my_custom_model/nixberry.onnx'\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/openwakeword/openwakeword/train.py\", line 913, in <module>\n",
      "    convert_onnx_to_tflite(os.path.join(config[\"output_dir\"], config[\"model_name\"] + \".onnx\"),\n",
      "  File \"/home/jovyan/openwakeword/openwakeword/train.py\", line 578, in convert_onnx_to_tflite\n",
      "    from onnx_tf.backend import prepare\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/onnx_tf/__init__.py\", line 1, in <module>\n",
      "    from . import backend\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/onnx_tf/backend.py\", line 21, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 29, in <module>\n",
      "    from tensorflow.core.framework import function_pb2\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 36, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 675, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train model\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/openwakeword')\n",
    "!PYTHONPATH=/home/jovyan/openwakeword:$PYTHONPATH python3 openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ebc97c-073f-4b94-a03d-255cc0b3855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting onnx==1.12.0\n",
      "  Downloading onnx-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting protobuf<=3.20.1,>=3.12.2\n",
      "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./.local/lib/python3.10/site-packages (from onnx==1.12.0) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./.local/lib/python3.10/site-packages (from onnx==1.12.0) (1.26.4)\n",
      "Installing collected packages: protobuf, onnx\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: onnx\n",
      "    Found existing installation: onnx 1.20.1\n",
      "    Uninstalling onnx-1.20.1:\n",
      "      Successfully uninstalled onnx-1.20.1\n",
      "\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "Successfully installed onnx-1.12.0 protobuf-3.20.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnx-tf==1.10.0 in ./.local/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: onnx>=1.10.2 in ./.local/lib/python3.10/site-packages (from onnx-tf==1.10.0) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-addons in ./.local/lib/python3.10/site-packages (from onnx-tf==1.10.0) (0.23.0)\n",
      "Requirement already satisfied: PyYAML in ./.local/lib/python3.10/site-packages (from onnx-tf==1.10.0) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./.local/lib/python3.10/site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (4.15.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow-addons->onnx-tf==1.10.0) (25.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in ./.local/lib/python3.10/site-packages (from tensorflow-addons->onnx-tf==1.10.0) (2.13.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow==2.11.0\n",
      "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (1.76.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (0.37.1)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (80.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (1.26.4)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (4.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (3.15.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (1.6.3)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (25.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (2.3.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (25.12.19)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (3.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (3.4.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (2.0.1)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (1.17.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.11.0) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.45.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.1.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.32.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.47.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2026.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.6.3)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.3.1)\n",
      "Installing collected packages: tensorflow-estimator, protobuf, keras, gast, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.7.0\n",
      "    Uninstalling gast-0.7.0:\n",
      "      Successfully uninstalled gast-0.7.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.8.1 requires keras<2.9,>=2.8.0rc0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-gpu 2.8.1 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-gpu 2.8.1 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.11.0 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires keras<2.9,>=2.8.0rc0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gast-0.4.0 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n",
      "IMPORTANT: Restart the kernel now (Kernel -> Restart Kernel), then run the next cell\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fix dependency conflicts and convert to tflite\n",
    "# Run this cell, then RESTART KERNEL\n",
    "\n",
    "import sys\n",
    "\n",
    "# Install compatible versions\n",
    "get_ipython().system(f'{sys.executable} -m pip install protobuf==3.20.3')\n",
    "get_ipython().system(f'{sys.executable} -m pip install onnx==1.12.0')\n",
    "get_ipython().system(f'{sys.executable} -m pip install onnx-tf==1.10.0')\n",
    "get_ipython().system(f'{sys.executable} -m pip install tensorflow==2.11.0')\n",
    "\n",
    "print(\"IMPORTANT: Restart the kernel now (Kernel -> Restart Kernel), then run the next cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "JSKWWLalnYzR",
   "metadata": {
    "id": "JSKWWLalnYzR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-gpu 2.8.1 requires keras<2.9,>=2.8.0rc0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-gpu 2.8.1 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-gpu 2.8.1 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.11.0 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires keras<2.9,>=2.8.0rc0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-cpu 2.8.1 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.11.0 which is incompatible.\n",
      "onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 10:45:39.207367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-18 10:45:39.370277: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-18 10:45:40.170021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2026-01-18 10:45:40.170158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2026-01-18 10:45:40.170168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2026-01-18 10:45:43.114802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:43.673740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:43.675421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:43.677531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-18 10:45:43.679428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:43.681026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:43.682324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:44.912137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "r/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:44.914616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2026-01-18 10:45:44.915738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13893 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `__call__` contains input name(s) onnx_tf__tf_Flatten_0_d1dbcd5f with unsupported characters which will be renamed to onnx_tf__tf_flatten_0_d1dbcd5f in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphqovpqxf/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphqovpqxf/tf_model/assets\n",
      "2026-01-18 10:45:48.309325: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2026-01-18 10:45:48.309360: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2026-01-18 10:45:48.310171: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmphqovpqxf/tf_model\n",
      "2026-01-18 10:45:48.311044: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2026-01-18 10:45:48.311079: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmphqovpqxf/tf_model\n",
      "2026-01-18 10:45:48.314108: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2026-01-18 10:45:48.314649: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2026-01-18 10:45:48.335327: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmphqovpqxf/tf_model\n",
      "2026-01-18 10:45:48.342888: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 32721 microseconds.\n",
      "2026-01-18 10:45:48.358159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-18 10:45:48.378437: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2111] Estimated count of arithmetic ops: 0.101 M  ops, equivalently 0.050 M  MACs\n"
     ]
    }
   ],
   "source": [
    "# Step 4 (Optional): On Google Colab, sometimes the .tflite model isn't saved correctly\n",
    "# If so, run this cell to retry\n",
    "\n",
    "# Fix protobuf compatibility issue first\n",
    "import sys\n",
    "get_ipython().system(f'{sys.executable} -m pip install protobuf==3.20.3')\n",
    "\n",
    "# Manually save to tflite as this doesn't work right in colab\n",
    "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
    "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
    "    # imports\n",
    "    import onnx\n",
    "    import logging\n",
    "    import tempfile\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Convert to tflite from onnx model\n",
    "    onnx_model = onnx.load(onnx_model_path)\n",
    "    tf_rep = prepare(onnx_model, device=\"GPU\")\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "    return None\n",
    "\n",
    "convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9OyUW3ltOSs",
   "metadata": {
    "id": "f9OyUW3ltOSs"
   },
   "source": [
    "After the model finishes training, the auto training script will automatically convert it to ONNX and tflite versions, saving them as `my_custom_model/<model_name>.onnx/tflite` in the present working directory, where `<model_name>` is defined in the YAML training config file. Either version can be used as normal with `openwakeword`. I recommend testing them with the [`detect_from_microphone.py`](https://github.com/dscripka/openWakeWord/blob/main/examples/detect_from_microphone.py) example script to see how the model performs!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
